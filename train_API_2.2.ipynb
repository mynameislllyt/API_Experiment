{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQtZoeX5d5IUThlxkCfMNA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynameislllyt/API_Experiment/blob/main/train_API_2.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ã€FP è¾ƒé«˜ï¼ˆè¯¯æŠ¥åå¤šï¼‰æ¨¡å‹å¯¹å¼‚å¸¸å¾ˆæ•æ„Ÿ\n",
        "Confusion matrix (è¡Œ=çœŸå®  åˆ—=é¢„æµ‹):\n",
        "[[ 1060  4330]\n",
        " [ 1664 23391]]\n",
        "Precision=0.8438, Recall=0.9336, F1=0.8864\n",
        "(Top-k = 5)"
      ],
      "metadata": {
        "id": "eIEpaveB5rXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUy8IFPiCvDm",
        "outputId": "ad1d4d9c-6d08-43ab-f5d5-f0c50153a2b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myting111_liu\u001b[0m (\u001b[33myting111_liu-southeast-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKNuJlMV28w5",
        "outputId": "80d1d16f-d37e-412b-8a5b-f99401b6057c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-26 06:45:04--  https://raw.githubusercontent.com/thpablo/Notebook_KNN_CSIC_Data/main/csicFinal.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21147547 (20M) [text/plain]\n",
            "Saving to: â€˜csicFinal.csvâ€™\n",
            "\n",
            "csicFinal.csv       100%[===================>]  20.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-11-26 06:45:05 (139 MB/s) - â€˜csicFinal.csvâ€™ saved [21147547/21147547]\n",
            "\n",
            "   Class Method                              URI Host-Header            Host  \\\n",
            "0  Valid    GET               /tienda1/index.jsp    HTTP/1.1  localhost:8080   \n",
            "1  Valid    GET      /tienda1/publico/anadir.jsp    HTTP/1.1  localhost:8080   \n",
            "2  Valid   POST      /tienda1/publico/anadir.jsp    HTTP/1.1  localhost:8080   \n",
            "3  Valid    GET  /tienda1/publico/autenticar.jsp    HTTP/1.1  localhost:8080   \n",
            "4  Valid   POST  /tienda1/publico/autenticar.jsp    HTTP/1.1  localhost:8080   \n",
            "\n",
            "  Connection                                             Accept  \\\n",
            "0      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "1      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "2      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "3      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "4      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "\n",
            "                Accept-Charset Accept-Language Cache-control  \\\n",
            "0  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "1  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "2  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "3  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "4  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "\n",
            "                                        Cookie    Pragma  Content-Length  \\\n",
            "0  JSESSIONID=EA414B3E327DED6875848530C864BD8F  no-cache             NaN   \n",
            "1  JSESSIONID=54E25FF4B7F0E4E855B112F882E9EEA5  no-cache             NaN   \n",
            "2  JSESSIONID=788887A0F479749C4CEEA1E268B4A501  no-cache            74.0   \n",
            "3  JSESSIONID=94ECD5EE8EF7EFE4BB26C701B150ED7B  no-cache             NaN   \n",
            "4  JSESSIONID=23391DBBADEC19FE01E02D201F278C6A  no-cache            60.0   \n",
            "\n",
            "                        Content-Type  \\\n",
            "0                                NaN   \n",
            "1                                NaN   \n",
            "2  application/x-www-form-urlencoded   \n",
            "3                                NaN   \n",
            "4  application/x-www-form-urlencoded   \n",
            "\n",
            "                                           POST-Data  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2  id=1&nombre=Jam%F3n+Ib%E9rico&precio=39&cantid...   \n",
            "3                                                NaN   \n",
            "4  modo=entrar&login=caria&pwd=egipciaca&remember...   \n",
            "\n",
            "                                           GET-Query  \n",
            "0                                                NaN  \n",
            "1  id=1&nombre=Jam%F3n+Ib%E9rico&precio=39&cantid...  \n",
            "2                                                NaN  \n",
            "3  modo=entrar&login=caria&pwd=egipciaca&remember...  \n",
            "4                                                NaN  \n",
            "Index(['Class', 'Method', 'URI', 'Host-Header', 'Host', 'Connection', 'Accept',\n",
            "       'Accept-Charset', 'Accept-Language', 'Cache-control', 'Cookie',\n",
            "       'Pragma', 'Content-Length', 'Content-Type', 'POST-Data', 'GET-Query'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# åœ¨ Colab ä¸­ä¸‹è½½ csicFinal.csv ï¼ˆåŸºäº CSIC 2010ï¼‰\n",
        "!wget -O csicFinal.csv https://raw.githubusercontent.com/thpablo/Notebook_KNN_CSIC_Data/main/csicFinal.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"csicFinal.csv\")\n",
        "print(df.head())#çœ‹å‰å‡ è¡Œ\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1. å¯¼å…¥åº“ & è¯»å–æ•°æ®\n",
        "# ===========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# å¦‚æœæ˜¯åœ¨ Colabï¼Œå¯ä»¥ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆå‡è®¾å·²ç» wget ä¸‹æ¥äº†ï¼‰\n",
        "CSV_PATH = \"csicFinal.csv\"   # æŒ‰ä½ å®é™…è·¯å¾„æ”¹\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"æ•°æ®ç»´åº¦:\", df.shape)\n",
        "print(\"åˆ—å:\", df.columns.tolist())\n",
        "\n",
        "print(\"\\nClass åˆ—å–å€¼ç»Ÿè®¡ï¼š\")\n",
        "print(df[\"Class\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AddvKTJJ3X_g",
        "outputId": "6a802ae5-fd79-4ef1-cba3-3438fed9d1e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ•°æ®ç»´åº¦: (61065, 16)\n",
            "åˆ—å: ['Class', 'Method', 'URI', 'Host-Header', 'Host', 'Connection', 'Accept', 'Accept-Charset', 'Accept-Language', 'Cache-control', 'Cookie', 'Pragma', 'Content-Length', 'Content-Type', 'POST-Data', 'GET-Query']\n",
            "\n",
            "Class åˆ—å–å€¼ç»Ÿè®¡ï¼š\n",
            "Class\n",
            "Valid        36000\n",
            "Anomalous    25065\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2. åˆ’åˆ†æ­£å¸¸ / å¼‚å¸¸ & æ•°æ®é›†\n",
        "# ===========================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "LABEL_COL = \"Class\"\n",
        "\n",
        "# å‡è®¾ normal æ˜¯æ ·æœ¬æœ€å¤šçš„é‚£ä¸ªç±»åˆ«ï¼ˆä¸€èˆ¬å°±æ˜¯ \"normal\"ï¼‰\n",
        "normal_label = df[LABEL_COL].value_counts().idxmax()\n",
        "print(\"æ¨æµ‹æ­£å¸¸æ ‡ç­¾ä¸º:\", normal_label)\n",
        "\n",
        "normal_df   = df[df[LABEL_COL] == normal_label].copy()\n",
        "abnormal_df = df[df[LABEL_COL] != normal_label].copy()\n",
        "\n",
        "print(\"normal æ ·æœ¬æ•°:\", len(normal_df))\n",
        "print(\"abnormal æ ·æœ¬æ•°:\", len(abnormal_df))\n",
        "\n",
        "# åœ¨ normal ä¸­åˆ’åˆ† train / val / test_normal\n",
        "train_norm, temp_norm = train_test_split(\n",
        "    normal_df, test_size=0.3, random_state=42, shuffle=True\n",
        ")\n",
        "val_norm, test_norm = train_test_split(\n",
        "    temp_norm, test_size=0.5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# å¼‚å¸¸å…¨éƒ¨åš test_abn\n",
        "test_abn = abnormal_df\n",
        "\n",
        "print(\"train_norm:\", len(train_norm))\n",
        "print(\"val_norm  :\", len(val_norm))\n",
        "print(\"test_norm :\", len(test_norm))\n",
        "print(\"test_abn  :\", len(test_abn))\n"
      ],
      "metadata": {
        "id": "ZTeyPn9k3dbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3. äº‹ä»¶æŠ½è±¡å‡½æ•°ï¼ˆMethod + URI æ¨¡æ¿ï¼‰\n",
        "# ===========================\n",
        "def template_uri(uri: str) -> str:\n",
        "    \"\"\"\n",
        "    æŠŠ URI å½’ä¸€åŒ–ï¼š\n",
        "    - å»æ‰ query (? åé¢)\n",
        "    - æŠŠæ•°å­—æ›¿æ¢æˆ <num>\n",
        "    \"\"\"\n",
        "    if pd.isna(uri):\n",
        "        uri = \"\"\n",
        "    uri = str(uri)\n",
        "\n",
        "    # å»æ‰ query\n",
        "    if \"?\" in uri:\n",
        "        uri = uri.split(\"?\", 1)[0]\n",
        "\n",
        "    # æŠŠè¿ç»­æ•°å­—æ›¿æ¢ä¸º <num>\n",
        "    uri = re.sub(r\"\\d+\", \"<num>\", uri)\n",
        "\n",
        "    return uri\n",
        "\n",
        "def row_to_event_str(row) -> str:\n",
        "    method = str(row.get(\"Method\", \"\")).upper()\n",
        "    uri_raw = row.get(\"URI\", \"\")\n",
        "    uri_t = template_uri(uri_raw)\n",
        "    event_str = f\"{method}|{uri_t}\"\n",
        "    return event_str\n",
        "\n",
        "# çœ‹çœ‹ç¤ºä¾‹\n",
        "print(\"\\nç¤ºä¾‹äº‹ä»¶ï¼š\")\n",
        "for i in range(5):\n",
        "    print(row_to_event_str(df.iloc[i]))\n"
      ],
      "metadata": {
        "id": "Geat_s-T3gFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 4. æ„å»ºäº‹ä»¶å­—å…¸ï¼ˆvocabï¼‰\n",
        "# ===========================\n",
        "# åªç”¨ train_norm ä¸­çš„äº‹ä»¶æ¥å»ºè¯è¡¨\n",
        "train_events_str = [row_to_event_str(row) for _, row in train_norm.iterrows()]\n",
        "\n",
        "counter = Counter(train_events_str)\n",
        "print(\"\\nä¸åŒäº‹ä»¶ä¸ªæ•°(è®­ç»ƒé›†):\", len(counter))\n",
        "\n",
        "# é¢„ç•™ç‰¹æ®Š token\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "event2id = {\n",
        "    PAD_TOKEN: 0,\n",
        "    UNK_TOKEN: 1,\n",
        "}\n",
        "id2event = {\n",
        "    0: PAD_TOKEN,\n",
        "    1: UNK_TOKEN,\n",
        "}\n",
        "\n",
        "for ev in counter:\n",
        "    idx = len(event2id)\n",
        "    event2id[ev] = idx\n",
        "    id2event[idx] = ev\n",
        "\n",
        "vocab_size = len(event2id)\n",
        "print(\"äº‹ä»¶å­—å…¸å¤§å°ï¼ˆå« PAD/UNKï¼‰:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQJITPs3kL-",
        "outputId": "07e8eab0-91b5-4a40-e257-aa9e0136819b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ä¸åŒäº‹ä»¶ä¸ªæ•°(è®­ç»ƒé›†): 34\n",
            "äº‹ä»¶å­—å…¸å¤§å°ï¼ˆå« PAD/UNKï¼‰: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5. DataFrame â†’ äº‹ä»¶ ID åºåˆ—\n",
        "# ===========================\n",
        "def df_to_event_ids(df_in, event2id):\n",
        "    ids = []\n",
        "    for _, row in df_in.iterrows():\n",
        "        ev_str = row_to_event_str(row)\n",
        "        ev_id = event2id.get(ev_str, event2id[UNK_TOKEN])\n",
        "        ids.append(ev_id)\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "train_ids = df_to_event_ids(train_norm, event2id)\n",
        "val_ids   = df_to_event_ids(val_norm,   event2id)\n",
        "test_norm_ids = df_to_event_ids(test_norm, event2id)\n",
        "test_abn_ids  = df_to_event_ids(test_abn,  event2id)\n",
        "\n",
        "print(\"train_ids shape:\", train_ids.shape)\n",
        "print(\"val_ids   shape:\", val_ids.shape)\n",
        "print(\"test_norm_ids shape:\", test_norm_ids.shape)\n",
        "print(\"test_abn_ids  shape:\", test_abn_ids.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkNv4YhO3oOB",
        "outputId": "eb4c0a46-a156-47a2-96cc-14568ae3835d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_ids shape: (25200,)\n",
            "val_ids   shape: (5400,)\n",
            "test_norm_ids shape: (5400,)\n",
            "test_abn_ids  shape: (25065,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 6. æ»‘åŠ¨çª—å£ Dataset\n",
        "# ===========================\n",
        "class EventWindowDataset(Dataset):\n",
        "    \"\"\"\n",
        "    input:  é•¿åº¦ä¸º L çš„äº‹ä»¶ ID åºåˆ—\n",
        "    target: ç¬¬ L+1 ä¸ªäº‹ä»¶ ID\n",
        "    ï¼ˆè®­ç»ƒã€éªŒè¯æ—¶ label=Noneï¼›æµ‹è¯•æ—¶å¯å¸¦ä¸Š 0/1 æ ‡ç­¾ï¼‰\n",
        "    \"\"\"\n",
        "    def __init__(self, event_ids: np.ndarray, window_size: int, label: int = None):\n",
        "        self.window_size = window_size\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "        labels = []\n",
        "\n",
        "        N = len(event_ids)\n",
        "        for i in range(N - window_size):\n",
        "            X_list.append(event_ids[i:i+window_size])\n",
        "            y_list.append(event_ids[i+window_size])\n",
        "            if label is not None:\n",
        "                labels.append(label)\n",
        "\n",
        "        self.X = torch.tensor(np.stack(X_list), dtype=torch.long)\n",
        "        self.y = torch.tensor(np.array(y_list), dtype=torch.long)\n",
        "        self.has_label = label is not None\n",
        "        if self.has_label:\n",
        "            self.labels = torch.tensor(np.array(labels), dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.has_label:\n",
        "            return self.X[idx], self.y[idx], self.labels[idx]\n",
        "        else:\n",
        "            return self.X[idx], self.y[idx]\n",
        "\n",
        "window_size = 10\n",
        "\n",
        "train_dataset = EventWindowDataset(train_ids, window_size=window_size, label=None)\n",
        "val_dataset   = EventWindowDataset(val_ids,   window_size=window_size, label=None)\n",
        "\n",
        "print(\"train windows:\", len(train_dataset))\n",
        "print(\"val windows  :\", len(val_dataset))\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "J6JI5iN-3snJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 7.x åˆå§‹åŒ– W&B å®éªŒ è®°ä½ä½ è¿™æ¬¡å®éªŒçš„æ‰€æœ‰è¶…å‚æ•°\n",
        "# ===========================\n",
        "import wandb  # ä¿é™©èµ·è§å† import ä¸€æ¬¡ä¹Ÿæ²¡é—®é¢˜\n",
        "\n",
        "PROJECT_NAME = \"csic_deeplog_api\"   # ä½ å¯ä»¥æ¢æˆè‡ªå·±å–œæ¬¢çš„é¡¹ç›®å\n",
        "RUN_NAME     = \"deeplog_lstm_v1\"    # æœ¬æ¬¡å®éªŒçš„åå­—ï¼ŒåŒºåˆ†ä¸åŒ run\n",
        "\n",
        "# æŠŠä¸»è¦è¶…å‚æ•°å†™è¿› configï¼Œæ–¹ä¾¿ä»¥åå¯¹æ¯”\n",
        "wandb_config = dict(\n",
        "    window_size = window_size,\n",
        "    batch_size  = batch_size,\n",
        "    num_epochs  = 10,          # ç­‰ä¼šè®­ç»ƒå¾ªç¯é‡Œçš„ num_epochs ä¹Ÿç”¨è¿™ä¸ª\n",
        "    embedding_dim = 64,\n",
        "    hidden_size   = 64,\n",
        "    lr            = 1e-3,\n",
        "    vocab_size    = vocab_size,\n",
        "    model_type    = \"DeepLogLSTM\",\n",
        ")\n",
        "\n",
        "run = wandb.init(\n",
        "    project = PROJECT_NAME,\n",
        "    name    = RUN_NAME,\n",
        "    config  = wandb_config,\n",
        "    reinit  = True,    # åŒä¸€ä¸ª kernel é‡Œå¤šæ¬¡ init æ—¶æœ‰ç”¨\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "4ddYaEyPHAPB",
        "outputId": "386b5164-8e6c-45ac-fce0-3ac947ef498d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251126_064533-0vrnv62u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api/runs/0vrnv62u' target=\"_blank\">deeplog_lstm_v1</a></strong> to <a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api' target=\"_blank\">https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api/runs/0vrnv62u' target=\"_blank\">https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api/runs/0vrnv62u</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 7. DeepLog é£æ ¼ LSTM æ¨¡å‹\n",
        "# ===========================\n",
        "class DeepLogLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [B, L] äº‹ä»¶ ID åºåˆ—\n",
        "        return: logits [B, vocab_size]ï¼Œå¯¹åº”ä¸‹ä¸€ä¸ªäº‹ä»¶çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆæœª softmaxï¼‰\n",
        "        \"\"\"\n",
        "        emb = self.embedding(x)           # [B, L, emb]\n",
        "        out, _ = self.lstm(emb)           # [B, L, hidden]\n",
        "        last_h = out[:, -1, :]            # [B, hidden]\n",
        "        logits = self.fc(last_h)          # [B, vocab_size]\n",
        "        return logits\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = DeepLogLSTM(vocab_size=vocab_size, embedding_dim=64, hidden_size=64, num_layers=1)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"æ¨¡å‹å‚æ•°é‡:\", total_params)\n"
      ],
      "metadata": {
        "id": "VlJtbUGf3t_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 8. è®­ç»ƒ & éªŒè¯\n",
        "# ===========================\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        logits = model(X_batch)          # [B, vocab_size]\n",
        "        loss = criterion(logits, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * X_batch.size(0)\n",
        "    return total_loss / len(train_dataset)\n",
        "\n",
        "def eval_one_epoch():\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_loss += loss.item() * X_batch.size(0)\n",
        "    return total_loss / len(val_dataset)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch()\n",
        "    val_loss = eval_one_epoch()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")\n",
        "\n",
        "# è®°å½•åˆ° W&B\n",
        "    wandb.log(\n",
        "        {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train/loss\": train_loss,\n",
        "            \"val/loss\": val_loss,\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "_MxGPDud33h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 9. æµ‹è¯•é›†çª—å£ï¼ˆæ­£å¸¸=0 / å¼‚å¸¸=1ï¼‰\n",
        "# ===========================\n",
        "test_norm_dataset = EventWindowDataset(test_norm_ids, window_size=window_size, label=0)\n",
        "test_abn_dataset  = EventWindowDataset(test_abn_ids,  window_size=window_size, label=1)\n",
        "\n",
        "# åˆå¹¶ä¸¤ä¸ªæµ‹è¯•é›†\n",
        "test_X = torch.cat([test_norm_dataset.X, test_abn_dataset.X], dim=0)\n",
        "test_y_next = torch.cat([test_norm_dataset.y, test_abn_dataset.y], dim=0)\n",
        "test_labels = torch.cat([test_norm_dataset.labels, test_abn_dataset.labels], dim=0)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(test_X, test_y_next, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "print(\"test windows:\", len(test_dataset))\n"
      ],
      "metadata": {
        "id": "uaxGXlbP4cbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 10. DeepLog Top-k å¼‚å¸¸æ£€æµ‹ & æŒ‡æ ‡\n",
        "# ===========================\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "k = 5  # Top-k\n",
        "\n",
        "all_true_labels = []\n",
        "all_pred_labels = []  # 0 æ­£å¸¸, 1 å¼‚å¸¸\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_next_batch, label_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_next_batch = y_next_batch.to(device)   # çœŸå®ä¸‹ä¸€äº‹ä»¶ ID\n",
        "        label_batch = label_batch.to(device)     # 0/1\n",
        "\n",
        "        logits = model(X_batch)                  # [B, vocab_size]\n",
        "        # å– top-k\n",
        "        topk_probs, topk_indices = torch.topk(F.softmax(logits, dim=1), k=k, dim=1)\n",
        "        # å¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œåˆ¤æ–­çœŸå® y_next æ˜¯å¦åœ¨ top-k é‡Œ\n",
        "        # bool tensor: True è¡¨ç¤º \"åœ¨ top-k å†…\" -> æ­£å¸¸; False -> å¼‚å¸¸\n",
        "        in_topk = (topk_indices == y_next_batch.unsqueeze(1)).any(dim=1)\n",
        "\n",
        "        # DeepLog è§„åˆ™ï¼šä¸åœ¨ top-k â†’ å¼‚å¸¸\n",
        "        pred_is_anomaly = (~in_topk).long()   # 1 å¼‚å¸¸, 0 æ­£å¸¸\n",
        "\n",
        "        all_true_labels.append(label_batch.cpu().numpy())\n",
        "        all_pred_labels.append(pred_is_anomaly.cpu().numpy())\n",
        "\n",
        "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
        "all_pred_labels = np.concatenate(all_pred_labels, axis=0)\n",
        "\n",
        "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "p, r, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='binary')\n",
        "\n",
        "print(\"Confusion matrix (è¡Œ=çœŸå®  åˆ—=é¢„æµ‹):\")\n",
        "print(cm)\n",
        "print(f\"Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "print(f\"(Top-k = {k})\")\n",
        "\n",
        "# æŠŠæµ‹è¯•æŒ‡æ ‡ä¹Ÿè®°å½•åˆ° W&B\n",
        "wandb.log(\n",
        "    {\n",
        "        \"test/precision\": float(p),\n",
        "        \"test/recall\": float(r),\n",
        "        \"test/f1\": float(f1),\n",
        "        \"test/top_k\": k,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJrAsGm04gMq",
        "outputId": "66452d50-0f73-4a83-fe40-5af1ebe3cdd4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (è¡Œ=çœŸå®  åˆ—=é¢„æµ‹):\n",
            "[[ 1035  4355]\n",
            " [ 2259 22796]]\n",
            "Precision=0.8396, Recall=0.9098, F1=0.8733\n",
            "(Top-k = 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Top-k å¯¹æ¯”å®éªŒä»£ç \n",
        "# ===========================\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# ç”¨ä¹‹å‰æ„é€ å¥½çš„ test_dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "# æƒ³æ¯”è¾ƒçš„ k å€¼\n",
        "k_list = [1, 3, 5, 8, 10, 15]\n",
        "\n",
        "results = []  # å­˜å„ä¸ª k çš„ç»“æœ\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬å…ˆæŠŠæ‰€æœ‰æ ·æœ¬çš„ logits å’ŒçœŸå® y_nextã€æ ‡ç­¾ä¸€æ¬¡æ€§ç®—å‡ºæ¥\n",
        "    all_logits = []\n",
        "    all_y_next = []\n",
        "    all_labels = []\n",
        "\n",
        "    for X_batch, y_next_batch, label_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_next_batch = y_next_batch.to(device)\n",
        "        label_batch = label_batch.to(device)\n",
        "\n",
        "        logits = model(X_batch)  # [B, vocab_size]\n",
        "\n",
        "        all_logits.append(logits.cpu())\n",
        "        all_y_next.append(y_next_batch.cpu())\n",
        "        all_labels.append(label_batch.cpu())\n",
        "\n",
        "    all_logits  = torch.cat(all_logits, dim=0)      # [N, vocab_size]\n",
        "    all_y_next  = torch.cat(all_y_next, dim=0)      # [N]\n",
        "    all_labels  = torch.cat(all_labels, dim=0)      # [N]\n",
        "\n",
        "# è½¬æˆ numpy æ–¹ä¾¿ sklearn å¤„ç†\n",
        "true_labels_np = all_labels.numpy()\n",
        "\n",
        "for k in k_list:\n",
        "    # å¯¹æ¯ä¸ª k å•ç‹¬è®¡ç®—ä¸€æ¬¡ in_topk / å¼‚å¸¸é¢„æµ‹\n",
        "    probs = F.softmax(all_logits, dim=1)  # [N, vocab_size]\n",
        "    topk_probs, topk_indices = torch.topk(probs, k=k, dim=1)\n",
        "\n",
        "    # åˆ¤æ–­çœŸå® y_next æ˜¯å¦åœ¨ top-k ä¸­\n",
        "    in_topk = (topk_indices == all_y_next.unsqueeze(1)).any(dim=1)  # [N] bool\n",
        "    pred_is_anomaly = (~in_topk).long().numpy()  # 1 å¼‚å¸¸, 0 æ­£å¸¸\n",
        "\n",
        "    cm = confusion_matrix(true_labels_np, pred_is_anomaly)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(true_labels_np, pred_is_anomaly,\n",
        "                                                  average='binary', zero_division=0)\n",
        "\n",
        "    results.append({\n",
        "        \"k\": k,\n",
        "        \"cm\": cm,\n",
        "        \"precision\": p,\n",
        "        \"recall\": r,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "\n",
        "    # ğŸ‘‰ æŠŠæ¯ä¸ª k çš„ç»“æœè®°å½•åˆ° W&B\n",
        "    wandb.log({\n",
        "        \"topk/k\": k,\n",
        "        \"topk/precision\": float(p),\n",
        "        \"topk/recall\": float(r),\n",
        "        \"topk/f1\": float(f1),\n",
        "    })\n",
        "\n",
        "    print(f\"\\n===== Top-k = {k} =====\")\n",
        "    print(\"Confusion matrix (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\")\n",
        "    print(cm)\n",
        "    print(f\"Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "print(\"\\n===== Top-k å¯¹æ¯”æ±‡æ€»ï¼ˆæ–¹ä¾¿å†™è®ºæ–‡ï¼‰ =====\")\n",
        "print(\"{:>6}  {:>9}  {:>9}  {:>9}\".format(\"k\", \"Precision\", \"Recall\", \"F1\"))\n",
        "for res in results:\n",
        "    print(\"{:>6}  {:>9.4f}  {:>9.4f}  {:>9.4f}\".format(\n",
        "        res[\"k\"], res[\"precision\"], res[\"recall\"], res[\"f1\"]\n",
        "    ))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVz-zQ3jKLQL",
        "outputId": "fec124b5-daf8-4243-85f8-e3ad8396f170"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Top-k = 1 =====\n",
            "Confusion matrix (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\n",
            "[[  443  4947]\n",
            " [  175 24880]]\n",
            "Precision=0.8341, Recall=0.9930, F1=0.9067\n",
            "\n",
            "===== Top-k = 3 =====\n",
            "Confusion matrix (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\n",
            "[[  745  4645]\n",
            " [ 1651 23404]]\n",
            "Precision=0.8344, Recall=0.9341, F1=0.8814\n",
            "\n",
            "===== Top-k = 5 =====\n",
            "Confusion matrix (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\n",
            "[[ 1035  4355]\n",
            " [ 2259 22796]]\n",
            "Precision=0.8396, Recall=0.9098, F1=0.8733\n",
            "\n",
            "===== Top-k = 8 =====\n",
            "Confusion matrix (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\n",
            "[[ 1477  3913]\n",
            " [ 2641 22414]]\n",
            "Precision=0.8514, Recall=0.8946, F1=0.8724\n",
            "\n",
            "===== Top-k = 10 =====\n",
            "Confusion matrix (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\n",
            "[[ 1769  3621]\n",
            " [ 3303 21752]]\n",
            "Precision=0.8573, Recall=0.8682, F1=0.8627\n",
            "\n",
            "===== Top-k = 15 =====\n",
            "Confusion matrix (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\n",
            "[[ 2527  2863]\n",
            " [ 6590 18465]]\n",
            "Precision=0.8658, Recall=0.7370, F1=0.7962\n",
            "\n",
            "===== Top-k å¯¹æ¯”æ±‡æ€»ï¼ˆæ–¹ä¾¿å†™è®ºæ–‡ï¼‰ =====\n",
            "     k  Precision     Recall         F1\n",
            "     1     0.8341     0.9930     0.9067\n",
            "     3     0.8344     0.9341     0.8814\n",
            "     5     0.8396     0.9098     0.8733\n",
            "     8     0.8514     0.8946     0.8724\n",
            "    10     0.8573     0.8682     0.8627\n",
            "    15     0.8658     0.7370     0.7962\n"
          ]
        }
      ]
    }
  ]
}