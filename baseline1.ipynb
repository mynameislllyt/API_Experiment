{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOeY2TVouMIcRTiqfd29ues",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynameislllyt/API_Experiment/blob/main/baseline1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoB8agpSlq7B",
        "outputId": "44a11eeb-763d-49d1-8d9d-77caf2849b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size: 307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 266/266 [00:01<00:00, 228.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1: train=1.8520, val=1.2503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 266/266 [00:01<00:00, 254.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2: train=1.0113, val=1.0165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 266/266 [00:01<00:00, 250.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3: train=0.8115, val=0.9100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 266/266 [00:01<00:00, 253.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4: train=0.6887, val=0.8509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 266/266 [00:01<00:00, 184.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5: train=0.6006, val=0.8179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 266/266 [00:01<00:00, 237.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6: train=0.5302, val=0.7976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 266/266 [00:01<00:00, 249.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7: train=0.4732, val=0.7841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 266/266 [00:01<00:00, 219.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8: train=0.4222, val=0.7668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 266/266 [00:01<00:00, 249.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9: train=0.3794, val=0.7680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 266/266 [00:01<00:00, 251.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10: train=0.3415, val=0.7597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 266/266 [00:01<00:00, 251.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11: train=0.3084, val=0.7681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 266/266 [00:01<00:00, 250.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12: train=0.2778, val=0.7635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 266/266 [00:01<00:00, 249.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13: train=0.2550, val=0.7754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 266/266 [00:01<00:00, 215.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14: train=0.2309, val=0.7812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 266/266 [00:01<00:00, 168.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15: train=0.2110, val=0.7924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 266/266 [00:01<00:00, 247.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16: train=0.1954, val=0.8056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 266/266 [00:01<00:00, 247.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17: train=0.1815, val=0.8170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 266/266 [00:01<00:00, 247.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18: train=0.1708, val=0.8263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 266/266 [00:01<00:00, 245.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep19: train=0.1602, val=0.8318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 266/266 [00:01<00:00, 248.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep20: train=0.1533, val=0.8320\n",
            "best_th: 2.4233922958374023\n",
            "{'acc': np.float64(0.2894871437206424), 'precision': np.float64(0.9991025536427348), 'recall': np.float64(0.2861415519779357), 'f1': np.float64(0.4448723068431505), 'fpr': np.float64(0.05069124423939774), 'tp': 12246, 'tn': 206, 'fp': 11, 'fn': 30551}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============ 1. 读数据 + 拆 benign-only ============\n",
        "def load_csv_expanded(path):\n",
        "    df = pd.read_csv(path)\n",
        "    seq_cols = [c for c in df.columns if c.startswith(\"t_\")]\n",
        "    seqs = df[seq_cols].values.astype(int)      # shape: [N, 100]\n",
        "    labels = df[\"malware\"].values.astype(int)   # 1=malware, 0=benign\n",
        "    return seqs, labels\n",
        "\n",
        "def split_benign_only(seqs, labels, seed=42):\n",
        "    benign = seqs[labels == 0]\n",
        "    malware = seqs[labels == 1]\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.permutation(len(benign))\n",
        "\n",
        "    n = len(benign)\n",
        "    n_train = int(0.7*n)\n",
        "    n_val   = int(0.1*n)\n",
        "\n",
        "    train = benign[idx[:n_train]]\n",
        "    val   = benign[idx[n_train:n_train+n_val]]\n",
        "    test_benign = benign[idx[n_train+n_val:]]\n",
        "    test_malware = malware\n",
        "    return train, val, test_benign, test_malware\n",
        "\n",
        "# ============ 2. 滑动窗口 ============\n",
        "def make_windows(seqs, window_size=10):\n",
        "    X, y = [], []\n",
        "    for s in seqs:\n",
        "        s = s.tolist()\n",
        "        for i in range(len(s) - window_size):\n",
        "            X.append(s[i:i+window_size])\n",
        "            y.append(s[i+window_size])\n",
        "    return np.array(X, dtype=int), np.array(y, dtype=int)\n",
        "\n",
        "# ============ 3. Dataset ============\n",
        "class WindowDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "# ============ 4. LSTM LM ============\n",
        "class LSTMLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "            dropout=dropout if num_layers>1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.emb(x)        # [B, W, E]\n",
        "        o, _ = self.lstm(e)    # [B, W, H]\n",
        "        last = o[:, -1, :]\n",
        "        return self.fc(last)   # [B, V]\n",
        "\n",
        "# ============ 5. 训练/验证 ============\n",
        "def eval_loss(model, loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            total += crit(model(Xb), yb).item()\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=20, lr=1e-3, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val, best_state = 1e9, None\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for Xb, yb in tqdm(train_loader, desc=f\"Epoch {ep}\"):\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = crit(model(Xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.item() * Xb.size(0)\n",
        "\n",
        "        val_loss = eval_loss(model, val_loader, device)\n",
        "        print(f\"ep{ep}: train={total/len(train_loader.dataset):.4f}, val={val_loss:.4f}\")\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "# ============ 6. 序列 NLL 异常分数 ============\n",
        "def sequence_scores_nll(model, seqs, window_size=10, device=\"cuda\"):#score 越大 = 越不符合 benign 模式 = 越可疑\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    model.eval()\n",
        "    scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for s in seqs:\n",
        "            X, y = make_windows([s], window_size)\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            y = torch.tensor(y, dtype=torch.long).to(device)\n",
        "            nll = crit(model(X), y)\n",
        "            scores.append(nll.mean().item())\n",
        "    return np.array(scores)\n",
        "\n",
        "def search_best_threshold(benign_scores, malware_scores):\n",
        "    all_scores = np.concatenate([benign_scores, malware_scores])\n",
        "    cand_th = np.quantile(all_scores, np.linspace(0.7, 0.99, 20))  # 可以调范围\n",
        "\n",
        "    best_f1, best_th, best_metrics = -1, None, None\n",
        "    for th in cand_th:\n",
        "        m = evaluate(th, benign_scores, malware_scores)\n",
        "        if m[\"f1\"] > best_f1:\n",
        "            best_f1, best_th, best_metrics = m[\"f1\"], th, m\n",
        "    return best_th, best_metrics\n",
        "\n",
        "def pick_threshold(val_scores, q=0.99):#在验证集上，大约 99% 的 benign score 都 低于 这个阈值\n",
        "    return float(np.quantile(val_scores, q))\n",
        "\n",
        "def evaluate(th, benign_scores, malware_scores):\n",
        "    y_true = np.array([0]*len(benign_scores) + [1]*len(malware_scores))\n",
        "    y_pred = np.array(\n",
        "        [1 if s>th else 0 for s in benign_scores] +\n",
        "        [1 if s>th else 0 for s in malware_scores]\n",
        "    )\n",
        "    tp = ((y_true==1)&(y_pred==1)).sum()\n",
        "    tn = ((y_true==0)&(y_pred==0)).sum()\n",
        "    fp = ((y_true==0)&(y_pred==1)).sum()\n",
        "    fn = ((y_true==1)&(y_pred==0)).sum()\n",
        "\n",
        "    precision = tp/(tp+fp+1e-9)\n",
        "    recall    = tp/(tp+fn+1e-9)\n",
        "    f1        = 2*precision*recall/(precision+recall+1e-9)\n",
        "    acc       = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "    fpr       = fp/(fp+tn+1e-9)\n",
        "    return dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "\n",
        "# ============ 7. 主流程 ============\n",
        "def main():\n",
        "    path = \"./dynamic_api_call_sequence_per_malware_100_0_306.csv\"\n",
        "    seqs, labels = load_csv_expanded(path)\n",
        "    train, val, test_benign, test_malware = split_benign_only(seqs, labels)\n",
        "\n",
        "    # vocab_size 需要从 token 最大值推出来（+1，因为从0计数）\n",
        "    vocab_size = int(seqs.max()) + 1\n",
        "    print(\"vocab_size:\", vocab_size)\n",
        "\n",
        "    window_size = 10\n",
        "    Xtr, ytr = make_windows(train, window_size)\n",
        "    Xva, yva = make_windows(val, window_size)\n",
        "\n",
        "    train_loader = DataLoader(WindowDataset(Xtr, ytr), batch_size=256, shuffle=True)\n",
        "    val_loader   = DataLoader(WindowDataset(Xva, yva), batch_size=256)\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = LSTMLM(vocab_size=vocab_size)\n",
        "    model = train_model(model, train_loader, val_loader, device=device)\n",
        "\n",
        "    val_scores = sequence_scores_nll(model, val, window_size, device=device)\n",
        "    # th = pick_threshold(val_scores, q=0.99)\n",
        "    # print(\"threshold:\", th)\n",
        "\n",
        "    benign_scores  = sequence_scores_nll(model, test_benign, window_size, device=device)\n",
        "    malware_scores = sequence_scores_nll(model, test_malware, window_size, device=device)\n",
        "    best_th, best_metrics = search_best_threshold(benign_scores, malware_scores)\n",
        "    print(\"best_th:\", best_th)\n",
        "    print(best_metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}