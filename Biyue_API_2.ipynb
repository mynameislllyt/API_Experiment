{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQMQRVaV2L6Oc1JIM+bjNe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynameislllyt/API_Experiment/blob/main/Biyue_API_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhr9iXnUR_rf",
        "outputId": "e1124cc9-5c52-421f-9f82-8eb39e30a553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/API_Detection (2).zip\" -d /content\n",
        "%cd /content/API_Detection\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJcdf1SeTOsf",
        "outputId": "0e304859-b6cb-456b-9e66-1d7693445029"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/API_Detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -U pip\n",
        "!grep -vE \"^(torch|torchvision|torchaudio)\\b\" requirements.txt > requirements_notorch.txt\n",
        "!pip install -r requirements_notorch.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IGKVWvjTSSX",
        "outputId": "0e57a1f9-a45f-4bb6-90a5-50eef1a85950"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_notorch.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_notorch.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_notorch.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_notorch.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_notorch.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_notorch.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_notorch.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_notorch.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_notorch.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements_notorch.txt (line 3)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements_notorch.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements_notorch.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_notorch.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_notorch.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_notorch.txt (line 4)) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_notorch.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_notorch.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_notorch.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_notorch.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements_notorch.txt (line 2)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -n \"ReduceLROnPlateau\" -n src/data_strengthen.py\n",
        "!sed -i -E \"s/, *verbose *= *[A-Za-z]+//g; s/verbose *= *[A-Za-z]+, *//g\" src/data_strengthen.py\n",
        "!grep -n \"ReduceLROnPlateau\" -n src/data_strengthen.py\n",
        "!python src/data_strengthen.py --data_path data/dynamic_api_call_sequence_per_malware_100_0_306.csv --epochs 20 --batch_size 64 --lr 1e-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbT9BgH7iW23",
        "outputId": "47c2f2d6-fb0a-4ddd-a846-253298d3acd5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "292:    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
            "292:    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
            "使用设备: cuda\n",
            "\n",
            "==================================================\n",
            "步骤 1: 加载数据\n",
            "==================================================\n",
            "数据集统计:\n",
            "  样本数量: 43876\n",
            "  序列长度: 100\n",
            "  API词汇表大小: 307\n",
            "  正常样本数: 1079\n",
            "  异常样本数: 42797\n",
            "\n",
            "==================================================\n",
            "步骤 2: 数据预处理和增强\n",
            "==================================================\n",
            "\n",
            "数据集划分:\n",
            "  正常样本: 1079\n",
            "  异常样本: 42797\n",
            "滑动窗口生成:\n",
            "  原始样本数: 863\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 78533\n",
            "滑动窗口生成:\n",
            "  原始样本数: 216\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 19656\n",
            "滑动窗口生成:\n",
            "  原始样本数: 42797\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 3894527\n",
            "\n",
            "最终数据集:\n",
            "  训练窗口数: 78533 (全部为正常样本)\n",
            "  测试窗口数: 3914183\n",
            "    - 正常: 19656\n",
            "    - 异常: 3894527\n",
            "\n",
            "⚠ 注意: 正常样本数量较少 (78533 窗口)\n",
            "将使用数据增强来增加训练样本...\n",
            "\n",
            "数据增强:\n",
            "  原始样本数: 78533\n",
            "  增强倍数: 5\n",
            "  增强后样本数: 471198 (增加了 392665 个)\n",
            "\n",
            "==================================================\n",
            "步骤 3: 创建TE-LSTM模型\n",
            "==================================================\n",
            "模型参数:\n",
            "  词汇表大小: 307\n",
            "  模型维度: 128\n",
            "  Dropout: 0.3 (高dropout防止过拟合)\n",
            "  总参数量: 566,707\n",
            "\n",
            "==================================================\n",
            "步骤 4: 训练模型（使用正则化）\n",
            "==================================================\n",
            "\n",
            "Epoch 1/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:33<00:00, 78.55it/s, loss=0.0035, l2=75.20]\n",
            "Train Loss: 0.0889 | Val Loss: 0.0026\n",
            "✓ 保存最佳模型 (Val Loss: 0.0026)\n",
            "\n",
            "Epoch 2/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.63it/s, loss=0.0053, l2=64.62]\n",
            "Train Loss: 0.0079 | Val Loss: 0.0020\n",
            "✓ 保存最佳模型 (Val Loss: 0.0020)\n",
            "\n",
            "Epoch 3/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:33<00:00, 78.39it/s, loss=0.0073, l2=62.07]\n",
            "Train Loss: 0.0067 | Val Loss: 0.0021\n",
            "\n",
            "Epoch 4/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:32<00:00, 79.63it/s, loss=0.0113, l2=60.60]\n",
            "Train Loss: 0.0064 | Val Loss: 0.0020\n",
            "\n",
            "Epoch 5/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.61it/s, loss=0.0072, l2=63.64]\n",
            "Train Loss: 0.0063 | Val Loss: 0.0020\n",
            "✓ 保存最佳模型 (Val Loss: 0.0020)\n",
            "\n",
            "Epoch 6/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:32<00:00, 79.53it/s, loss=0.0050, l2=59.55]\n",
            "Train Loss: 0.0061 | Val Loss: 0.0018\n",
            "✓ 保存最佳模型 (Val Loss: 0.0018)\n",
            "\n",
            "Epoch 7/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:32<00:00, 79.36it/s, loss=0.0031, l2=59.12]\n",
            "Train Loss: 0.0059 | Val Loss: 0.0019\n",
            "\n",
            "Epoch 8/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:32<00:00, 79.76it/s, loss=0.0121, l2=58.93]\n",
            "Train Loss: 0.0057 | Val Loss: 0.0016\n",
            "✓ 保存最佳模型 (Val Loss: 0.0016)\n",
            "\n",
            "Epoch 9/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:32<00:00, 79.77it/s, loss=0.0037, l2=58.75]\n",
            "Train Loss: 0.0057 | Val Loss: 0.0014\n",
            "✓ 保存最佳模型 (Val Loss: 0.0014)\n",
            "\n",
            "Epoch 10/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:32<00:00, 79.81it/s, loss=0.0070, l2=58.08]\n",
            "Train Loss: 0.0054 | Val Loss: 0.0014\n",
            "✓ 保存最佳模型 (Val Loss: 0.0014)\n",
            "\n",
            "Epoch 11/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.71it/s, loss=0.0050, l2=59.62]\n",
            "Train Loss: 0.0053 | Val Loss: 0.0013\n",
            "✓ 保存最佳模型 (Val Loss: 0.0013)\n",
            "\n",
            "Epoch 12/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.76it/s, loss=0.0034, l2=58.56]\n",
            "Train Loss: 0.0053 | Val Loss: 0.0013\n",
            "\n",
            "Epoch 13/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.71it/s, loss=0.0082, l2=57.97]\n",
            "Train Loss: 0.0052 | Val Loss: 0.0013\n",
            "\n",
            "Epoch 14/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.77it/s, loss=0.0065, l2=58.07]\n",
            "Train Loss: 0.0052 | Val Loss: 0.0013\n",
            "✓ 保存最佳模型 (Val Loss: 0.0013)\n",
            "\n",
            "Epoch 15/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.74it/s, loss=0.0060, l2=58.57]\n",
            "Train Loss: 0.0053 | Val Loss: 0.0013\n",
            "\n",
            "Epoch 16/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.77it/s, loss=0.0044, l2=58.54]\n",
            "Train Loss: 0.0052 | Val Loss: 0.0013\n",
            "\n",
            "Epoch 17/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.86it/s, loss=0.0095, l2=57.77]\n",
            "Train Loss: 0.0052 | Val Loss: 0.0013\n",
            "\n",
            "Epoch 18/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:30<00:00, 80.98it/s, loss=0.0020, l2=57.89]\n",
            "Train Loss: 0.0052 | Val Loss: 0.0011\n",
            "✓ 保存最佳模型 (Val Loss: 0.0011)\n",
            "\n",
            "Epoch 19/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.62it/s, loss=0.0029, l2=58.18]\n",
            "Train Loss: 0.0052 | Val Loss: 0.0011\n",
            "\n",
            "Epoch 20/20\n",
            "--------------------------------------------------\n",
            "Training: 100% 7362/7362 [01:31<00:00, 80.87it/s, loss=0.0034, l2=57.83]\n",
            "Train Loss: 0.0052 | Val Loss: 0.0013\n",
            "\n",
            "训练历史图保存至: results/training_history_augmented.png\n",
            "\n",
            "==================================================\n",
            "步骤 5: 自适应阈值搜索\n",
            "==================================================\n",
            "\n",
            "计算训练集重构误差...\n",
            "训练集误差统计:\n",
            "  均值: 0.001131\n",
            "  中位数: 0.000120\n",
            "  标准差: 0.011375\n",
            "\n",
            "推荐阈值:\n",
            "  90百分位: 0.001146\n",
            "  95百分位: 0.002370\n",
            "  99百分位: 0.015669\n",
            "  99.5百分位: 0.033760\n",
            "\n",
            "阈值信息保存至: models/threshold_augmented.json\n",
            "\n",
            "==================================================\n",
            "增强训练完成!\n",
            "==================================================\n",
            "最佳验证损失: 0.0011\n",
            "\n",
            "原始样本数: 78533\n",
            "增强后样本数: 471198\n",
            "\n",
            "模型保存于: models\n",
            "建议使用以下阈值测试:\n",
            "  90百分位: 0.001146\n",
            "  95百分位: 0.002370\n",
            "  99百分位: 0.015669\n",
            "  99.5百分位: 0.033760\n",
            "\n",
            "下一步:\n",
            "1. 使用多个阈值评估:\n",
            "   python src/evaluate.py --model_path models/te_lstm_best_augmented.pth --data_path data/dynamic_api_call_sequence_per_malware_100_0_306.csv\n",
            "2. 优化阈值:\n",
            "   python src/optimize_threshold.py --model_path models/te_lstm_best_augmented.pth --data_path data/dynamic_api_call_sequence_per_malware_100_0_306.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/API_Detection/src/optimize_threshold.py\n",
        "\"\"\"\n",
        "阈值优化脚本 - 搜索最优异常检测阈值\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 如果在Colab，添加路径\n",
        "import sys\n",
        "if '/content' in os.getcwd():\n",
        "    sys.path.append('/content/src')\n",
        "\n",
        "from data_preprocessing import load_api_data, prepare_train_test_data, create_dataloaders\n",
        "from model import TELSTM\n",
        "\n",
        "\n",
        "def find_optimal_threshold(model, test_loader, device, method='f1'):\n",
        "    \"\"\"\n",
        "    搜索最优阈值\n",
        "\n",
        "    核心逻辑：\n",
        "    1. 计算所有测试样本的重构误差\n",
        "    2. 尝试不同的阈值（从50%到99.9%分位数）\n",
        "    3. 找到使F1分数最大的阈值\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_errors = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"计算测试集重构误差...\")\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader):\n",
        "            x, labels = batch\n",
        "            x = x.to(device)\n",
        "\n",
        "            # 计算每个样本的重构误差\n",
        "            errors = model.compute_reconstruction_error(x, reduction='mean')\n",
        "            all_errors.extend(errors.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    all_errors = np.array(all_errors)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    print(f\"\\n误差统计:\")\n",
        "    print(f\"  范围: [{all_errors.min():.6f}, {all_errors.max():.6f}]\")\n",
        "    print(f\"  均值: {all_errors.mean():.6f}\")\n",
        "    print(f\"  中位数: {np.median(all_errors):.6f}\")\n",
        "\n",
        "    # 生成候选阈值\n",
        "    percentiles = np.linspace(50, 99.9, 100)\n",
        "    thresholds = np.percentile(all_errors, percentiles)\n",
        "\n",
        "    # 搜索最优阈值\n",
        "    best_score = -1\n",
        "    best_threshold = None\n",
        "    results = []\n",
        "\n",
        "    print(\"\\n搜索最优阈值...\")\n",
        "    for threshold in tqdm(thresholds):\n",
        "        predictions = (all_errors > threshold).astype(int)\n",
        "\n",
        "        precision = precision_score(all_labels, predictions, zero_division=0)\n",
        "        recall = recall_score(all_labels, predictions, zero_division=0)\n",
        "        f1 = f1_score(all_labels, predictions, zero_division=0)\n",
        "\n",
        "        score = f1 if method == 'f1' else (precision + recall) / 2\n",
        "\n",
        "        results.append({\n",
        "            'threshold': threshold,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'score': score\n",
        "        })\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold, results\n",
        "\n",
        "\n",
        "def plot_threshold_curve(results, best_threshold, save_path):\n",
        "    \"\"\"绘制阈值-性能曲线\"\"\"\n",
        "    thresholds = [r['threshold'] for r in results]\n",
        "    precisions = [r['precision'] for r in results]\n",
        "    recalls = [r['recall'] for r in results]\n",
        "    f1s = [r['f1'] for r in results]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # 全局视图\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(thresholds, precisions, 'b-', label='Precision', linewidth=2)\n",
        "    plt.plot(thresholds, recalls, 'r-', label='Recall', linewidth=2)\n",
        "    plt.plot(thresholds, f1s, 'g-', label='F1-Score', linewidth=2)\n",
        "    plt.axvline(best_threshold, color='k', linestyle='--',\n",
        "                label=f'Best={best_threshold:.6f}', linewidth=2)\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Metrics vs Threshold')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xscale('log')\n",
        "\n",
        "    # 局部放大\n",
        "    plt.subplot(1, 2, 2)\n",
        "    idx = np.argmin(np.abs(np.array(thresholds) - best_threshold))\n",
        "    start, end = max(0, idx-20), min(len(thresholds), idx+20)\n",
        "\n",
        "    plt.plot(thresholds[start:end], precisions[start:end], 'b-', label='Precision', linewidth=2)\n",
        "    plt.plot(thresholds[start:end], recalls[start:end], 'r-', label='Recall', linewidth=2)\n",
        "    plt.plot(thresholds[start:end], f1s[start:end], 'g-', label='F1-Score', linewidth=2)\n",
        "    plt.axvline(best_threshold, color='k', linestyle='--', linewidth=2)\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Zoomed View')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"阈值曲线已保存: {save_path}\")\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"使用设备: {device}\")\n",
        "\n",
        "    # 加载模型\n",
        "    print(\"\\n加载模型...\")\n",
        "    checkpoint = torch.load(args.model_path, map_location=device)\n",
        "    model_args = checkpoint['args']\n",
        "    vocab_size = checkpoint['vocab_size']\n",
        "\n",
        "    model = TELSTM(\n",
        "        vocab_size=vocab_size,\n",
        "        d_model=model_args['d_model'],\n",
        "        nhead=model_args['nhead'],\n",
        "        num_encoder_layers=model_args['num_layers'],\n",
        "        lstm_hidden=model_args['lstm_hidden'],\n",
        "        dropout=model_args['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # 加载数据\n",
        "    print(\"\\n加载数据...\")\n",
        "    df, _ = load_api_data(args.data_path)\n",
        "    train_windows, test_windows, test_labels = prepare_train_test_data(\n",
        "        df,\n",
        "        window_size=model_args['window_size'],\n",
        "        test_ratio=model_args['test_ratio'],\n",
        "        random_state=model_args['seed']\n",
        "    )\n",
        "\n",
        "    _, test_loader = create_dataloaders(\n",
        "        train_windows, test_windows, test_labels,\n",
        "        batch_size=args.batch_size\n",
        "    )\n",
        "\n",
        "    # 搜索最优阈值\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"搜索最优阈值\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    best_threshold, results = find_optimal_threshold(\n",
        "        model, test_loader, device, method=args.method\n",
        "    )\n",
        "\n",
        "    print(f\"\\n✓ 最优阈值: {best_threshold:.6f}\")\n",
        "\n",
        "    # 保存结果\n",
        "    os.makedirs(args.result_dir, exist_ok=True)\n",
        "\n",
        "    threshold_info = {\n",
        "        'optimal_threshold': float(best_threshold),\n",
        "        'method': args.method\n",
        "    }\n",
        "\n",
        "    threshold_path = os.path.join(args.result_dir, 'optimal_threshold.json')\n",
        "    with open(threshold_path, 'w') as f:\n",
        "        json.dump(threshold_info, f, indent=4)\n",
        "    print(f\"阈值已保存: {threshold_path}\")\n",
        "\n",
        "    # 更新模型目录的阈值\n",
        "    model_dir = os.path.dirname(args.model_path)\n",
        "    model_threshold_path = os.path.join(model_dir, 'threshold.json')\n",
        "    with open(model_threshold_path, 'w') as f:\n",
        "        json.dump({'threshold': float(best_threshold), 'percentile': None}, f, indent=4)\n",
        "    print(f\"模型阈值已更新: {model_threshold_path}\")\n",
        "\n",
        "    # 绘制曲线\n",
        "    plot_path = os.path.join(args.result_dir, 'threshold_analysis.png')\n",
        "    plot_threshold_curve(results, best_threshold, plot_path)\n",
        "\n",
        "    print(\"\\n✓ 优化完成！\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='优化异常检测阈值')\n",
        "\n",
        "    parser.add_argument('--model_path', type=str, required=True,\n",
        "                       help='模型文件路径')\n",
        "    parser.add_argument('--data_path', type=str, required=True,\n",
        "                       help='数据集路径')\n",
        "    parser.add_argument('--batch_size', type=int, default=32,\n",
        "                       help='批次大小')\n",
        "    parser.add_argument('--method', type=str, default='f1',\n",
        "                       choices=['f1', 'balanced'],\n",
        "                       help='优化目标')\n",
        "    parser.add_argument('--result_dir', type=str, default='results',\n",
        "                       help='结果保存目录')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main(args)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOkkpH3vrjhU",
        "outputId": "040eb62a-0b32-43fd-9410-fbc4d355b003"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/API_Detection/src/optimize_threshold.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式2：使用命令行\n",
        "!python /content/API_Detection/src/optimize_threshold.py \\\n",
        "    --model_path /content/API_Detection/models/te_lstm_best_augmented.pth \\\n",
        "    --data_path /content/API_Detection/data/dynamic_api_call_sequence_per_malware_100_0_306.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omRL3C9utwl5",
        "outputId": "47da9961-4eea-4fbe-aaa4-526447c313cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用设备: cuda\n",
            "\n",
            "加载模型...\n",
            "\n",
            "加载数据...\n",
            "数据集统计:\n",
            "  样本数量: 43876\n",
            "  序列长度: 100\n",
            "  API词汇表大小: 307\n",
            "  正常样本数: 1079\n",
            "  异常样本数: 42797\n",
            "\n",
            "数据集划分:\n",
            "  正常样本: 1079\n",
            "  异常样本: 42797\n",
            "滑动窗口生成:\n",
            "  原始样本数: 863\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 78533\n",
            "滑动窗口生成:\n",
            "  原始样本数: 216\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 19656\n",
            "滑动窗口生成:\n",
            "  原始样本数: 42797\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 3894527\n",
            "\n",
            "最终数据集:\n",
            "  训练窗口数: 78533 (全部为正常样本)\n",
            "  测试窗口数: 3914183\n",
            "    - 正常: 19656\n",
            "    - 异常: 3894527\n",
            "\n",
            "==================================================\n",
            "搜索最优阈值\n",
            "==================================================\n",
            "计算测试集重构误差...\n",
            "100% 122319/122319 [04:08<00:00, 491.91it/s]\n",
            "\n",
            "误差统计:\n",
            "  范围: [0.000011, 9.994293]\n",
            "  均值: 0.022278\n",
            "  中位数: 0.000196\n",
            "\n",
            "搜索最优阈值...\n",
            "100% 100/100 [00:50<00:00,  1.97it/s]\n",
            "\n",
            "✓ 最优阈值: 0.000196\n",
            "阈值已保存: results/optimal_threshold.json\n",
            "模型阈值已更新: /content/API_Detection/models/threshold.json\n",
            "阈值曲线已保存: results/threshold_analysis.png\n",
            "\n",
            "✓ 优化完成！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/evaluate.py\n",
        "\"\"\"\n",
        "模型评估脚本 - 完整的性能评估\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_curve, auc\n",
        ")\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sys\n",
        "if '/content' in os.getcwd():\n",
        "    sys.path.append('/content/src')\n",
        "\n",
        "from data_preprocessing import load_api_data, prepare_train_test_data, create_dataloaders\n",
        "from model import TELSTM\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_loader, threshold, device):\n",
        "    \"\"\"评估模型性能\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_errors = []\n",
        "\n",
        "    print(\"评估中...\")\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader):\n",
        "            x, labels = batch\n",
        "            x = x.to(device)\n",
        "\n",
        "            # 计算重构误差\n",
        "            errors = model.compute_reconstruction_error(x, reduction='mean')\n",
        "\n",
        "            # 基于阈值判断异常\n",
        "            predictions = (errors > threshold).long()\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_errors.extend(errors.cpu().numpy())\n",
        "\n",
        "    return np.array(all_predictions), np.array(all_labels), np.array(all_errors)\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, save_path):\n",
        "    \"\"\"绘制混淆矩阵\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Normal', 'Anomaly'],\n",
        "                yticklabels=['Normal', 'Anomaly'])\n",
        "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"混淆矩阵已保存: {save_path}\")\n",
        "\n",
        "\n",
        "def plot_roc_curve(labels, errors, save_path):\n",
        "    \"\"\"绘制ROC曲线\"\"\"\n",
        "    fpr, tpr, _ = roc_curve(labels, errors)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"ROC曲线已保存: {save_path}\")\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "def plot_error_distribution(labels, errors, threshold, save_path):\n",
        "    \"\"\"绘制误差分布\"\"\"\n",
        "    normal_errors = errors[labels == 0]\n",
        "    anomaly_errors = errors[labels == 1]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(normal_errors, bins=50, alpha=0.6, label='Normal',\n",
        "             color='green', density=True)\n",
        "    plt.hist(anomaly_errors, bins=50, alpha=0.6, label='Anomaly',\n",
        "             color='red', density=True)\n",
        "    plt.axvline(threshold, color='black', linestyle='--', linewidth=2,\n",
        "                label=f'Threshold={threshold:.6f}')\n",
        "    plt.xlabel('Reconstruction Error')\n",
        "    plt.ylabel('Density')\n",
        "    plt.title('Error Distribution', fontsize=14, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"误差分布已保存: {save_path}\")\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"使用设备: {device}\")\n",
        "\n",
        "    # 加载模型\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"加载模型\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    checkpoint = torch.load(args.model_path, map_location=device)\n",
        "    model_args = checkpoint['args']\n",
        "    vocab_size = checkpoint['vocab_size']\n",
        "\n",
        "    model = TELSTM(\n",
        "        vocab_size=vocab_size,\n",
        "        d_model=model_args['d_model'],\n",
        "        nhead=model_args['nhead'],\n",
        "        num_encoder_layers=model_args['num_layers'],\n",
        "        lstm_hidden=model_args['lstm_hidden'],\n",
        "        dropout=model_args['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"✓ 模型已加载: {args.model_path}\")\n",
        "\n",
        "    # 加载阈值\n",
        "    model_dir = os.path.dirname(args.model_path)\n",
        "    threshold_path = os.path.join(model_dir, 'threshold.json')\n",
        "\n",
        "    if os.path.exists(threshold_path):\n",
        "        with open(threshold_path, 'r') as f:\n",
        "            threshold_info = json.load(f)\n",
        "            threshold = threshold_info['threshold']\n",
        "        print(f\"✓ 使用阈值: {threshold:.6f}\")\n",
        "    else:\n",
        "        print(\"⚠ 未找到阈值文件，使用默认值 0.0004\")\n",
        "        threshold = 0.0004\n",
        "\n",
        "    # 加载数据\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"加载数据\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    df, _ = load_api_data(args.data_path)\n",
        "    train_windows, test_windows, test_labels = prepare_train_test_data(\n",
        "        df,\n",
        "        window_size=model_args['window_size'],\n",
        "        test_ratio=model_args['test_ratio'],\n",
        "        random_state=model_args['seed']\n",
        "    )\n",
        "\n",
        "    _, test_loader = create_dataloaders(\n",
        "        train_windows, test_windows, test_labels,\n",
        "        batch_size=args.batch_size\n",
        "    )\n",
        "\n",
        "    # 评估\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"评估模型\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    predictions, labels, errors = evaluate_model(\n",
        "        model, test_loader, threshold, device\n",
        "    )\n",
        "\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision = precision_score(labels, predictions, zero_division=0)\n",
        "    recall = recall_score(labels, predictions, zero_division=0)\n",
        "    f1 = f1_score(labels, predictions, zero_division=0)\n",
        "    cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(labels, errors)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # 打印结果\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"评估结果\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\n准确率 (Accuracy):  {accuracy:.4f}\")\n",
        "    print(f\"精确率 (Precision): {precision:.4f}\")\n",
        "    print(f\"召回率 (Recall):    {recall:.4f}\")\n",
        "    print(f\"F1分数 (F1-Score):  {f1:.4f}\")\n",
        "    print(f\"AUC-ROC:            {roc_auc:.4f}\")\n",
        "\n",
        "    print(f\"\\n混淆矩阵:\")\n",
        "    print(f\"                预测正常  预测异常\")\n",
        "    print(f\"实际正常    {cm[0, 0]:>8}  {cm[0, 1]:>8}\")\n",
        "    print(f\"实际异常    {cm[1, 0]:>8}  {cm[1, 1]:>8}\")\n",
        "\n",
        "    # 误差统计\n",
        "    normal_errors = errors[labels == 0]\n",
        "    anomaly_errors = errors[labels == 1]\n",
        "\n",
        "    print(f\"\\n误差统计:\")\n",
        "    print(f\"正常样本: {normal_errors.mean():.4f} (±{normal_errors.std():.4f})\")\n",
        "    print(f\"异常样本: {anomaly_errors.mean():.4f} (±{anomaly_errors.std():.4f})\")\n",
        "\n",
        "    # 保存结果\n",
        "    os.makedirs(args.result_dir, exist_ok=True)\n",
        "\n",
        "    # 保存指标\n",
        "    metrics = {\n",
        "        'accuracy': float(accuracy),\n",
        "        'precision': float(precision),\n",
        "        'recall': float(recall),\n",
        "        'f1_score': float(f1),\n",
        "        'auc': float(roc_auc),\n",
        "        'threshold': float(threshold),\n",
        "        'confusion_matrix': cm.tolist()\n",
        "    }\n",
        "\n",
        "    metrics_path = os.path.join(args.result_dir, 'evaluation_metrics.json')\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        json.dump(metrics, f, indent=4)\n",
        "    print(f\"\\n✓ 指标已保存: {metrics_path}\")\n",
        "\n",
        "    # 保存详细报告\n",
        "    report = classification_report(labels, predictions,\n",
        "                                   target_names=['Normal', 'Anomaly'])\n",
        "    report_path = os.path.join(args.result_dir, 'classification_report.txt')\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(report)\n",
        "    print(f\"✓ 详细报告已保存: {report_path}\")\n",
        "\n",
        "    # 绘制图表\n",
        "    print(\"\\n生成可视化...\")\n",
        "    plot_confusion_matrix(cm, os.path.join(args.result_dir, 'confusion_matrix.png'))\n",
        "    plot_roc_curve(labels, errors, os.path.join(args.result_dir, 'roc_curve.png'))\n",
        "    plot_error_distribution(labels, errors, threshold,\n",
        "                           os.path.join(args.result_dir, 'error_distribution.png'))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"评估完成！\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"结果保存于: {args.result_dir}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='评估TE-LSTM模型')\n",
        "\n",
        "    parser.add_argument('--model_path', type=str, required=True,\n",
        "                       help='模型文件路径')\n",
        "    parser.add_argument('--data_path', type=str, required=True,\n",
        "                       help='数据集路径')\n",
        "    parser.add_argument('--batch_size', type=int, default=32,\n",
        "                       help='批次大小')\n",
        "    parser.add_argument('--result_dir', type=str, default='results',\n",
        "                       help='结果保存目录')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ze1RgshxEQQ",
        "outputId": "1f25486d-94fd-49a1-d357-e4bb1dee00b0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/evaluate.py --model_path models/te_lstm_best_augmented.pth --data_path data/dynamic_api_call_sequence_per_malware_100_0_306.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEaxSfH2wci2",
        "outputId": "57305a21-860e-4014-caf1-310dca424ce5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用设备: cuda\n",
            "\n",
            "==================================================\n",
            "加载模型\n",
            "==================================================\n",
            "✓ 模型已加载: models/te_lstm_best_augmented.pth\n",
            "✓ 使用阈值: 0.000196\n",
            "\n",
            "==================================================\n",
            "加载数据\n",
            "==================================================\n",
            "数据集统计:\n",
            "  样本数量: 43876\n",
            "  序列长度: 100\n",
            "  API词汇表大小: 307\n",
            "  正常样本数: 1079\n",
            "  异常样本数: 42797\n",
            "\n",
            "数据集划分:\n",
            "  正常样本: 1079\n",
            "  异常样本: 42797\n",
            "滑动窗口生成:\n",
            "  原始样本数: 863\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 78533\n",
            "滑动窗口生成:\n",
            "  原始样本数: 216\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 19656\n",
            "滑动窗口生成:\n",
            "  原始样本数: 42797\n",
            "  窗口大小: 10\n",
            "  生成窗口数: 3894527\n",
            "\n",
            "最终数据集:\n",
            "  训练窗口数: 78533 (全部为正常样本)\n",
            "  测试窗口数: 3914183\n",
            "    - 正常: 19656\n",
            "    - 异常: 3894527\n",
            "\n",
            "==================================================\n",
            "评估模型\n",
            "==================================================\n",
            "评估中...\n",
            "100% 122319/122319 [04:17<00:00, 474.37it/s]\n",
            "\n",
            "==================================================\n",
            "评估结果\n",
            "==================================================\n",
            "\n",
            "准确率 (Accuracy):  0.4993\n",
            "精确率 (Precision): 0.9961\n",
            "召回率 (Recall):    0.4987\n",
            "F1分数 (F1-Score):  0.6646\n",
            "AUC-ROC:            0.5926\n",
            "\n",
            "混淆矩阵:\n",
            "                预测正常  预测异常\n",
            "实际正常       12115      7541\n",
            "实际异常     1952479   1942048\n",
            "\n",
            "误差统计:\n",
            "正常样本: 0.0028 (±0.0426)\n",
            "异常样本: 0.0224 (±0.2052)\n",
            "\n",
            "✓ 指标已保存: results/evaluation_metrics.json\n",
            "✓ 详细报告已保存: results/classification_report.txt\n",
            "\n",
            "生成可视化...\n",
            "混淆矩阵已保存: results/confusion_matrix.png\n",
            "ROC曲线已保存: results/roc_curve.png\n",
            "误差分布已保存: results/error_distribution.png\n",
            "\n",
            "==================================================\n",
            "评估完成！\n",
            "==================================================\n",
            "结果保存于: results\n"
          ]
        }
      ]
    }
  ]
}