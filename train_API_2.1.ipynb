{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr+SvsyzimI3zpyP8b/blj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynameislllyt/API_Experiment/blob/main/train_API_2.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1、FP 较高（误报偏多）模型对异常很敏感\n",
        "Confusion matrix (行=真实  列=预测):\n",
        "[[ 1060  4330]\n",
        " [ 1664 23391]]\n",
        "Precision=0.8438, Recall=0.9336, F1=0.8864\n",
        "(Top-k = 5)"
      ],
      "metadata": {
        "id": "eIEpaveB5rXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUy8IFPiCvDm",
        "outputId": "75bb66ee-ac8d-4fdc-8da0-1f833985ba64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myting111_liu\u001b[0m (\u001b[33myting111_liu-southeast-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cKNuJlMV28w5",
        "outputId": "732a0578-6cdd-4867-c628-c77ef410dfc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-25 11:53:47--  https://raw.githubusercontent.com/thpablo/Notebook_KNN_CSIC_Data/main/csicFinal.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21147547 (20M) [text/plain]\n",
            "Saving to: ‘csicFinal.csv’\n",
            "\n",
            "csicFinal.csv       100%[===================>]  20.17M  53.6MB/s    in 0.4s    \n",
            "\n",
            "2025-11-25 11:53:48 (53.6 MB/s) - ‘csicFinal.csv’ saved [21147547/21147547]\n",
            "\n",
            "   Class Method                              URI Host-Header            Host  \\\n",
            "0  Valid    GET               /tienda1/index.jsp    HTTP/1.1  localhost:8080   \n",
            "1  Valid    GET      /tienda1/publico/anadir.jsp    HTTP/1.1  localhost:8080   \n",
            "2  Valid   POST      /tienda1/publico/anadir.jsp    HTTP/1.1  localhost:8080   \n",
            "3  Valid    GET  /tienda1/publico/autenticar.jsp    HTTP/1.1  localhost:8080   \n",
            "4  Valid   POST  /tienda1/publico/autenticar.jsp    HTTP/1.1  localhost:8080   \n",
            "\n",
            "  Connection                                             Accept  \\\n",
            "0      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "1      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "2      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "3      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "4      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "\n",
            "                Accept-Charset Accept-Language Cache-control  \\\n",
            "0  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "1  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "2  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "3  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "4  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "\n",
            "                                        Cookie    Pragma  Content-Length  \\\n",
            "0  JSESSIONID=EA414B3E327DED6875848530C864BD8F  no-cache             NaN   \n",
            "1  JSESSIONID=54E25FF4B7F0E4E855B112F882E9EEA5  no-cache             NaN   \n",
            "2  JSESSIONID=788887A0F479749C4CEEA1E268B4A501  no-cache            74.0   \n",
            "3  JSESSIONID=94ECD5EE8EF7EFE4BB26C701B150ED7B  no-cache             NaN   \n",
            "4  JSESSIONID=23391DBBADEC19FE01E02D201F278C6A  no-cache            60.0   \n",
            "\n",
            "                        Content-Type  \\\n",
            "0                                NaN   \n",
            "1                                NaN   \n",
            "2  application/x-www-form-urlencoded   \n",
            "3                                NaN   \n",
            "4  application/x-www-form-urlencoded   \n",
            "\n",
            "                                           POST-Data  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2  id=1&nombre=Jam%F3n+Ib%E9rico&precio=39&cantid...   \n",
            "3                                                NaN   \n",
            "4  modo=entrar&login=caria&pwd=egipciaca&remember...   \n",
            "\n",
            "                                           GET-Query  \n",
            "0                                                NaN  \n",
            "1  id=1&nombre=Jam%F3n+Ib%E9rico&precio=39&cantid...  \n",
            "2                                                NaN  \n",
            "3  modo=entrar&login=caria&pwd=egipciaca&remember...  \n",
            "4                                                NaN  \n",
            "Index(['Class', 'Method', 'URI', 'Host-Header', 'Host', 'Connection', 'Accept',\n",
            "       'Accept-Charset', 'Accept-Language', 'Cache-control', 'Cookie',\n",
            "       'Pragma', 'Content-Length', 'Content-Type', 'POST-Data', 'GET-Query'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# 在 Colab 中下载 csicFinal.csv （基于 CSIC 2010）\n",
        "!wget -O csicFinal.csv https://raw.githubusercontent.com/thpablo/Notebook_KNN_CSIC_Data/main/csicFinal.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"csicFinal.csv\")\n",
        "print(df.head())\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1. 导入库 & 读取数据\n",
        "# ===========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# 如果是在 Colab，可以用相对路径（假设已经 wget 下来了）\n",
        "CSV_PATH = \"csicFinal.csv\"   # 按你实际路径改\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"数据维度:\", df.shape)\n",
        "print(\"列名:\", df.columns.tolist())\n",
        "\n",
        "print(\"\\nClass 列取值统计：\")\n",
        "print(df[\"Class\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AddvKTJJ3X_g",
        "outputId": "e252cd7f-2ffe-4832-ba5f-c5df101ef806"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据维度: (61065, 16)\n",
            "列名: ['Class', 'Method', 'URI', 'Host-Header', 'Host', 'Connection', 'Accept', 'Accept-Charset', 'Accept-Language', 'Cache-control', 'Cookie', 'Pragma', 'Content-Length', 'Content-Type', 'POST-Data', 'GET-Query']\n",
            "\n",
            "Class 列取值统计：\n",
            "Class\n",
            "Valid        36000\n",
            "Anomalous    25065\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2. 划分正常 / 异常 & 数据集\n",
        "# ===========================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "LABEL_COL = \"Class\"\n",
        "\n",
        "# 假设 normal 是样本最多的那个类别（一般就是 \"normal\"）\n",
        "normal_label = df[LABEL_COL].value_counts().idxmax()\n",
        "print(\"推测正常标签为:\", normal_label)\n",
        "\n",
        "normal_df   = df[df[LABEL_COL] == normal_label].copy()\n",
        "abnormal_df = df[df[LABEL_COL] != normal_label].copy()\n",
        "\n",
        "print(\"normal 样本数:\", len(normal_df))\n",
        "print(\"abnormal 样本数:\", len(abnormal_df))\n",
        "\n",
        "# 在 normal 中划分 train / val / test_normal\n",
        "train_norm, temp_norm = train_test_split(\n",
        "    normal_df, test_size=0.3, random_state=42, shuffle=True\n",
        ")\n",
        "val_norm, test_norm = train_test_split(\n",
        "    temp_norm, test_size=0.5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# 异常全部做 test_abn\n",
        "test_abn = abnormal_df\n",
        "\n",
        "print(\"train_norm:\", len(train_norm))\n",
        "print(\"val_norm  :\", len(val_norm))\n",
        "print(\"test_norm :\", len(test_norm))\n",
        "print(\"test_abn  :\", len(test_abn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTeyPn9k3dbz",
        "outputId": "04575fbd-9396-49b6-a8d7-03453ef649e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "推测正常标签为: Valid\n",
            "normal 样本数: 36000\n",
            "abnormal 样本数: 25065\n",
            "train_norm: 25200\n",
            "val_norm  : 5400\n",
            "test_norm : 5400\n",
            "test_abn  : 25065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3. 事件抽象函数（Method + URI 模板）\n",
        "# ===========================\n",
        "def template_uri(uri: str) -> str:\n",
        "    \"\"\"\n",
        "    把 URI 归一化：\n",
        "    - 去掉 query (? 后面)\n",
        "    - 把数字替换成 <num>\n",
        "    \"\"\"\n",
        "    if pd.isna(uri):\n",
        "        uri = \"\"\n",
        "    uri = str(uri)\n",
        "\n",
        "    # 去掉 query\n",
        "    if \"?\" in uri:\n",
        "        uri = uri.split(\"?\", 1)[0]\n",
        "\n",
        "    # 把连续数字替换为 <num>\n",
        "    uri = re.sub(r\"\\d+\", \"<num>\", uri)\n",
        "\n",
        "    return uri\n",
        "\n",
        "def row_to_event_str(row) -> str:\n",
        "    method = str(row.get(\"Method\", \"\")).upper()\n",
        "    uri_raw = row.get(\"URI\", \"\")\n",
        "    uri_t = template_uri(uri_raw)\n",
        "    event_str = f\"{method}|{uri_t}\"\n",
        "    return event_str\n",
        "\n",
        "# 看看示例\n",
        "print(\"\\n示例事件：\")\n",
        "for i in range(5):\n",
        "    print(row_to_event_str(df.iloc[i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Geat_s-T3gFI",
        "outputId": "032c87d7-336e-46f5-fb2c-c172e0ea2e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "示例事件：\n",
            "GET|/tienda<num>/index.jsp\n",
            "GET|/tienda<num>/publico/anadir.jsp\n",
            "POST|/tienda<num>/publico/anadir.jsp\n",
            "GET|/tienda<num>/publico/autenticar.jsp\n",
            "POST|/tienda<num>/publico/autenticar.jsp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 4. 构建事件字典（vocab）\n",
        "# ===========================\n",
        "# 只用 train_norm 中的事件来建词表\n",
        "train_events_str = [row_to_event_str(row) for _, row in train_norm.iterrows()]\n",
        "\n",
        "counter = Counter(train_events_str)\n",
        "print(\"\\n不同事件个数(训练集):\", len(counter))\n",
        "\n",
        "# 预留特殊 token\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "event2id = {\n",
        "    PAD_TOKEN: 0,\n",
        "    UNK_TOKEN: 1,\n",
        "}\n",
        "id2event = {\n",
        "    0: PAD_TOKEN,\n",
        "    1: UNK_TOKEN,\n",
        "}\n",
        "\n",
        "for ev in counter:\n",
        "    idx = len(event2id)\n",
        "    event2id[ev] = idx\n",
        "    id2event[idx] = ev\n",
        "\n",
        "vocab_size = len(event2id)\n",
        "print(\"事件字典大小（含 PAD/UNK）:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQJITPs3kL-",
        "outputId": "452e891a-70ef-4f26-d211-3455bf8501d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "不同事件个数(训练集): 34\n",
            "事件字典大小（含 PAD/UNK）: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5. DataFrame → 事件 ID 序列\n",
        "# ===========================\n",
        "def df_to_event_ids(df_in, event2id):\n",
        "    ids = []\n",
        "    for _, row in df_in.iterrows():\n",
        "        ev_str = row_to_event_str(row)\n",
        "        ev_id = event2id.get(ev_str, event2id[UNK_TOKEN])\n",
        "        ids.append(ev_id)\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "train_ids = df_to_event_ids(train_norm, event2id)\n",
        "val_ids   = df_to_event_ids(val_norm,   event2id)\n",
        "test_norm_ids = df_to_event_ids(test_norm, event2id)\n",
        "test_abn_ids  = df_to_event_ids(test_abn,  event2id)\n",
        "\n",
        "print(\"train_ids shape:\", train_ids.shape)\n",
        "print(\"val_ids   shape:\", val_ids.shape)\n",
        "print(\"test_norm_ids shape:\", test_norm_ids.shape)\n",
        "print(\"test_abn_ids  shape:\", test_abn_ids.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkNv4YhO3oOB",
        "outputId": "6fddc2fe-6b3b-4c98-fcde-fb366dcb5c49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_ids shape: (25200,)\n",
            "val_ids   shape: (5400,)\n",
            "test_norm_ids shape: (5400,)\n",
            "test_abn_ids  shape: (25065,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 6. 滑动窗口 Dataset\n",
        "# ===========================\n",
        "class EventWindowDataset(Dataset):\n",
        "    \"\"\"\n",
        "    input:  长度为 L 的事件 ID 序列\n",
        "    target: 第 L+1 个事件 ID\n",
        "    （训练、验证时 label=None；测试时可带上 0/1 标签）\n",
        "    \"\"\"\n",
        "    def __init__(self, event_ids: np.ndarray, window_size: int, label: int = None):\n",
        "        self.window_size = window_size\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "        labels = []\n",
        "\n",
        "        N = len(event_ids)\n",
        "        for i in range(N - window_size):\n",
        "            X_list.append(event_ids[i:i+window_size])\n",
        "            y_list.append(event_ids[i+window_size])\n",
        "            if label is not None:\n",
        "                labels.append(label)\n",
        "\n",
        "        self.X = torch.tensor(np.stack(X_list), dtype=torch.long)\n",
        "        self.y = torch.tensor(np.array(y_list), dtype=torch.long)\n",
        "        self.has_label = label is not None\n",
        "        if self.has_label:\n",
        "            self.labels = torch.tensor(np.array(labels), dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.has_label:\n",
        "            return self.X[idx], self.y[idx], self.labels[idx]\n",
        "        else:\n",
        "            return self.X[idx], self.y[idx]\n",
        "\n",
        "window_size = 10\n",
        "\n",
        "train_dataset = EventWindowDataset(train_ids, window_size=window_size, label=None)\n",
        "val_dataset   = EventWindowDataset(val_ids,   window_size=window_size, label=None)\n",
        "\n",
        "print(\"train windows:\", len(train_dataset))\n",
        "print(\"val windows  :\", len(val_dataset))\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6JI5iN-3snJ",
        "outputId": "716611f6-1180-443f-fd05-f3fad69fc0a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train windows: 25190\n",
            "val windows  : 5390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 7.x 初始化 W&B 实验 记住你这次实验的所有超参数\n",
        "# ===========================\n",
        "import wandb  # 保险起见再 import 一次也没问题\n",
        "\n",
        "PROJECT_NAME = \"csic_deeplog_api\"   # 你可以换成自己喜欢的项目名\n",
        "RUN_NAME     = \"deeplog_lstm_v1\"    # 本次实验的名字，区分不同 run\n",
        "\n",
        "# 把主要超参数写进 config，方便以后对比\n",
        "wandb_config = dict(\n",
        "    window_size = window_size,\n",
        "    batch_size  = batch_size,\n",
        "    num_epochs  = 10,          # 等会训练循环里的 num_epochs 也用这个\n",
        "    embedding_dim = 64,\n",
        "    hidden_size   = 64,\n",
        "    lr            = 1e-3,\n",
        "    vocab_size    = vocab_size,\n",
        "    model_type    = \"DeepLogLSTM\",\n",
        ")\n",
        "\n",
        "run = wandb.init(\n",
        "    project = PROJECT_NAME,\n",
        "    name    = RUN_NAME,\n",
        "    config  = wandb_config,\n",
        "    reinit  = True,    # 同一个 kernel 里多次 init 时有用\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "4ddYaEyPHAPB",
        "outputId": "f16ed5fa-2d5a-465d-937e-2cf7723e8c12"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251125_130259-63q0jj0q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api/runs/63q0jj0q' target=\"_blank\">deeplog_lstm_v1</a></strong> to <a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api' target=\"_blank\">https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api/runs/63q0jj0q' target=\"_blank\">https://wandb.ai/yting111_liu-southeast-university/csic_deeplog_api/runs/63q0jj0q</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 7. DeepLog 风格 LSTM 模型\n",
        "# ===========================\n",
        "class DeepLogLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [B, L] 事件 ID 序列\n",
        "        return: logits [B, vocab_size]，对应下一个事件的概率分布（未 softmax）\n",
        "        \"\"\"\n",
        "        emb = self.embedding(x)           # [B, L, emb]\n",
        "        out, _ = self.lstm(emb)           # [B, L, hidden]\n",
        "        last_h = out[:, -1, :]            # [B, hidden]\n",
        "        logits = self.fc(last_h)          # [B, vocab_size]\n",
        "        return logits\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = DeepLogLSTM(vocab_size=vocab_size, embedding_dim=64, hidden_size=64, num_layers=1)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"模型参数量:\", total_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlJtbUGf3t_J",
        "outputId": "70689d95-7e26-47cf-e888-df31066eceaa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "模型参数量: 37924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 8. 训练 & 验证\n",
        "# ===========================\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        logits = model(X_batch)          # [B, vocab_size]\n",
        "        loss = criterion(logits, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * X_batch.size(0)\n",
        "    return total_loss / len(train_dataset)\n",
        "\n",
        "def eval_one_epoch():\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_loss += loss.item() * X_batch.size(0)\n",
        "    return total_loss / len(val_dataset)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch()\n",
        "    val_loss = eval_one_epoch()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")\n",
        "\n",
        "# 记录到 W&B\n",
        "    wandb.log(\n",
        "        {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train/loss\": train_loss,\n",
        "            \"val/loss\": val_loss,\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MxGPDud33h-",
        "outputId": "fb43f9fc-fc35-4bba-b1da-913c87e4b057"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - train_loss=3.533046, val_loss=3.509391\n",
            "Epoch 2/10 - train_loss=3.492361, val_loss=3.507019\n",
            "Epoch 3/10 - train_loss=3.485625, val_loss=3.507442\n",
            "Epoch 4/10 - train_loss=3.480199, val_loss=3.508900\n",
            "Epoch 5/10 - train_loss=3.474728, val_loss=3.512181\n",
            "Epoch 6/10 - train_loss=3.469034, val_loss=3.517491\n",
            "Epoch 7/10 - train_loss=3.462192, val_loss=3.520133\n",
            "Epoch 8/10 - train_loss=3.454956, val_loss=3.523377\n",
            "Epoch 9/10 - train_loss=3.446849, val_loss=3.527945\n",
            "Epoch 10/10 - train_loss=3.437160, val_loss=3.533455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 9. 测试集窗口（正常=0 / 异常=1）\n",
        "# ===========================\n",
        "test_norm_dataset = EventWindowDataset(test_norm_ids, window_size=window_size, label=0)\n",
        "test_abn_dataset  = EventWindowDataset(test_abn_ids,  window_size=window_size, label=1)\n",
        "\n",
        "# 合并两个测试集\n",
        "test_X = torch.cat([test_norm_dataset.X, test_abn_dataset.X], dim=0)\n",
        "test_y_next = torch.cat([test_norm_dataset.y, test_abn_dataset.y], dim=0)\n",
        "test_labels = torch.cat([test_norm_dataset.labels, test_abn_dataset.labels], dim=0)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(test_X, test_y_next, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "print(\"test windows:\", len(test_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaxGXlbP4cbZ",
        "outputId": "43f4c270-3221-4eea-84b7-7d509c91298f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test windows: 30445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 10. DeepLog Top-k 异常检测 & 指标\n",
        "# ===========================\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "k = 5  # Top-k\n",
        "\n",
        "all_true_labels = []\n",
        "all_pred_labels = []  # 0 正常, 1 异常\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_next_batch, label_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_next_batch = y_next_batch.to(device)   # 真实下一事件 ID\n",
        "        label_batch = label_batch.to(device)     # 0/1\n",
        "\n",
        "        logits = model(X_batch)                  # [B, vocab_size]\n",
        "        # 取 top-k\n",
        "        topk_probs, topk_indices = torch.topk(F.softmax(logits, dim=1), k=k, dim=1)\n",
        "        # 对于每个样本，判断真实 y_next 是否在 top-k 里\n",
        "        # bool tensor: True 表示 \"在 top-k 内\" -> 正常; False -> 异常\n",
        "        in_topk = (topk_indices == y_next_batch.unsqueeze(1)).any(dim=1)\n",
        "\n",
        "        # DeepLog 规则：不在 top-k → 异常\n",
        "        pred_is_anomaly = (~in_topk).long()   # 1 异常, 0 正常\n",
        "\n",
        "        all_true_labels.append(label_batch.cpu().numpy())\n",
        "        all_pred_labels.append(pred_is_anomaly.cpu().numpy())\n",
        "\n",
        "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
        "all_pred_labels = np.concatenate(all_pred_labels, axis=0)\n",
        "\n",
        "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "p, r, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='binary')\n",
        "\n",
        "print(\"Confusion matrix (行=真实  列=预测):\")\n",
        "print(cm)\n",
        "print(f\"Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "print(f\"(Top-k = {k})\")\n",
        "\n",
        "# 把测试指标也记录到 W&B\n",
        "wandb.log(\n",
        "    {\n",
        "        \"test/precision\": float(p),\n",
        "        \"test/recall\": float(r),\n",
        "        \"test/f1\": float(f1),\n",
        "        \"test/top_k\": k,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJrAsGm04gMq",
        "outputId": "49a446b3-3286-4961-b665-b95c1bc49dcc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (行=真实  列=预测):\n",
            "[[ 1038  4352]\n",
            " [  899 24156]]\n",
            "Precision=0.8473, Recall=0.9641, F1=0.9020\n",
            "(Top-k = 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Top-k 对比实验代码\n",
        "# ===========================\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# 用之前构造好的 test_dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "# 想比较的 k 值\n",
        "k_list = [1, 3, 5, 8, 10, 15]\n",
        "\n",
        "results = []  # 存各个 k 的结果\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # 为了效率，我们先把所有样本的 logits 和真实 y_next、标签一次性算出来\n",
        "    all_logits = []\n",
        "    all_y_next = []\n",
        "    all_labels = []\n",
        "\n",
        "    for X_batch, y_next_batch, label_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_next_batch = y_next_batch.to(device)\n",
        "        label_batch = label_batch.to(device)\n",
        "\n",
        "        logits = model(X_batch)  # [B, vocab_size]\n",
        "\n",
        "        all_logits.append(logits.cpu())\n",
        "        all_y_next.append(y_next_batch.cpu())\n",
        "        all_labels.append(label_batch.cpu())\n",
        "\n",
        "    all_logits  = torch.cat(all_logits, dim=0)      # [N, vocab_size]\n",
        "    all_y_next  = torch.cat(all_y_next, dim=0)      # [N]\n",
        "    all_labels  = torch.cat(all_labels, dim=0)      # [N]\n",
        "\n",
        "# 转成 numpy 方便 sklearn 处理\n",
        "true_labels_np = all_labels.numpy()\n",
        "\n",
        "for k in k_list:\n",
        "    # 对每个 k 单独计算一次 in_topk / 异常预测\n",
        "    probs = F.softmax(all_logits, dim=1)  # [N, vocab_size]\n",
        "    topk_probs, topk_indices = torch.topk(probs, k=k, dim=1)\n",
        "\n",
        "    # 判断真实 y_next 是否在 top-k 中\n",
        "    in_topk = (topk_indices == all_y_next.unsqueeze(1)).any(dim=1)  # [N] bool\n",
        "    pred_is_anomaly = (~in_topk).long().numpy()  # 1 异常, 0 正常\n",
        "\n",
        "    cm = confusion_matrix(true_labels_np, pred_is_anomaly)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(true_labels_np, pred_is_anomaly,\n",
        "                                                  average='binary', zero_division=0)\n",
        "\n",
        "    results.append({\n",
        "        \"k\": k,\n",
        "        \"cm\": cm,\n",
        "        \"precision\": p,\n",
        "        \"recall\": r,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "\n",
        "    print(f\"\\n===== Top-k = {k} =====\")\n",
        "    print(\"Confusion matrix (行=真实, 列=预测):\")\n",
        "    print(cm)\n",
        "    print(f\"Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "print(\"\\n===== Top-k 对比汇总（方便写论文） =====\")\n",
        "print(\"{:>6}  {:>9}  {:>9}  {:>9}\".format(\"k\", \"Precision\", \"Recall\", \"F1\"))\n",
        "for res in results:\n",
        "    print(\"{:>6}  {:>9.4f}  {:>9.4f}  {:>9.4f}\".format(\n",
        "        res[\"k\"], res[\"precision\"], res[\"recall\"], res[\"f1\"]\n",
        "    ))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVz-zQ3jKLQL",
        "outputId": "01825e47-9582-400c-9150-f70c44ef93dd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Top-k = 1 =====\n",
            "Confusion matrix (行=真实, 列=预测):\n",
            "[[  443  4947]\n",
            " [    1 25054]]\n",
            "Precision=0.8351, Recall=1.0000, F1=0.9101\n",
            "\n",
            "===== Top-k = 3 =====\n",
            "Confusion matrix (行=真实, 列=预测):\n",
            "[[  728  4662]\n",
            " [  171 24884]]\n",
            "Precision=0.8422, Recall=0.9932, F1=0.9115\n",
            "\n",
            "===== Top-k = 5 =====\n",
            "Confusion matrix (行=真实, 列=预测):\n",
            "[[ 1038  4352]\n",
            " [  899 24156]]\n",
            "Precision=0.8473, Recall=0.9641, F1=0.9020\n",
            "\n",
            "===== Top-k = 8 =====\n",
            "Confusion matrix (行=真实, 列=预测):\n",
            "[[ 1482  3908]\n",
            " [ 1892 23163]]\n",
            "Precision=0.8556, Recall=0.9245, F1=0.8887\n",
            "\n",
            "===== Top-k = 10 =====\n",
            "Confusion matrix (行=真实, 列=预测):\n",
            "[[ 1774  3616]\n",
            " [ 2406 22649]]\n",
            "Precision=0.8623, Recall=0.9040, F1=0.8827\n",
            "\n",
            "===== Top-k = 15 =====\n",
            "Confusion matrix (行=真实, 列=预测):\n",
            "[[ 2543  2847]\n",
            " [ 3691 21364]]\n",
            "Precision=0.8824, Recall=0.8527, F1=0.8673\n",
            "\n",
            "===== Top-k 对比汇总（方便写论文） =====\n",
            "     k  Precision     Recall         F1\n",
            "     1     0.8351     1.0000     0.9101\n",
            "     3     0.8422     0.9932     0.9115\n",
            "     5     0.8473     0.9641     0.9020\n",
            "     8     0.8556     0.9245     0.8887\n",
            "    10     0.8623     0.9040     0.8827\n",
            "    15     0.8824     0.8527     0.8673\n"
          ]
        }
      ]
    }
  ]
}