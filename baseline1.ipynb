{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpEwDnY9gHVPoYAFFNTBwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynameislllyt/API_Experiment/blob/main/baseline1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoB8agpSlq7B",
        "outputId": "129eefe8-2b57-432e-95cc-ed17fce4f2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size: 307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 236/236 [00:02<00:00, 111.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1: train=1.9311, val=1.3203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 236/236 [00:01<00:00, 152.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2: train=1.0468, val=1.0255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 236/236 [00:01<00:00, 166.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3: train=0.8269, val=0.9190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 236/236 [00:01<00:00, 147.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4: train=0.6962, val=0.8446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 236/236 [00:01<00:00, 156.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5: train=0.6014, val=0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 236/236 [00:01<00:00, 151.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6: train=0.5276, val=0.7851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 236/236 [00:01<00:00, 166.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7: train=0.4671, val=0.7624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 236/236 [00:01<00:00, 163.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8: train=0.4157, val=0.7605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 236/236 [00:01<00:00, 165.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9: train=0.3713, val=0.7404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 236/236 [00:01<00:00, 151.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10: train=0.3326, val=0.7462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 236/236 [00:01<00:00, 160.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11: train=0.2969, val=0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 236/236 [00:01<00:00, 144.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12: train=0.2675, val=0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 236/236 [00:01<00:00, 165.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13: train=0.2427, val=0.7518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 236/236 [00:01<00:00, 152.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14: train=0.2159, val=0.7715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 236/236 [00:01<00:00, 163.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15: train=0.1950, val=0.7826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 236/236 [00:01<00:00, 165.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16: train=0.1752, val=0.7952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 236/236 [00:01<00:00, 164.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17: train=0.1591, val=0.8117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 236/236 [00:01<00:00, 150.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18: train=0.1461, val=0.8094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 236/236 [00:01<00:00, 150.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep19: train=0.1335, val=0.8273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 236/236 [00:01<00:00, 151.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep20: train=0.1235, val=0.8379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 236/236 [00:01<00:00, 162.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep21: train=0.1157, val=0.8503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 236/236 [00:01<00:00, 149.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep22: train=0.1050, val=0.8720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 236/236 [00:01<00:00, 164.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep23: train=0.0996, val=0.8749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 236/236 [00:01<00:00, 164.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep24: train=0.0974, val=0.8853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 236/236 [00:01<00:00, 164.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep25: train=0.0945, val=0.9009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 236/236 [00:01<00:00, 148.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep26: train=0.0881, val=0.9184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 236/236 [00:01<00:00, 143.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep27: train=0.0844, val=0.9194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 236/236 [00:01<00:00, 162.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep28: train=0.0792, val=0.9318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 236/236 [00:01<00:00, 163.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep29: train=0.0773, val=0.9383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 236/236 [00:01<00:00, 149.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep30: train=0.0771, val=0.9323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|██████████| 236/236 [00:01<00:00, 162.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep31: train=0.0746, val=0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|██████████| 236/236 [00:01<00:00, 162.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep32: train=0.0730, val=0.9488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|██████████| 236/236 [00:01<00:00, 162.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep33: train=0.0703, val=0.9722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|██████████| 236/236 [00:01<00:00, 142.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep34: train=0.0741, val=0.9660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|██████████| 236/236 [00:01<00:00, 155.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep35: train=0.0740, val=0.9814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|██████████| 236/236 [00:01<00:00, 162.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep36: train=0.0710, val=0.9993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|██████████| 236/236 [00:01<00:00, 159.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep37: train=0.0659, val=0.9994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|██████████| 236/236 [00:01<00:00, 161.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep38: train=0.0634, val=1.0226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39: 100%|██████████| 236/236 [00:01<00:00, 161.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep39: train=0.0649, val=1.0109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40: 100%|██████████| 236/236 [00:01<00:00, 160.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep40: train=0.0666, val=1.0121\n",
            "threshold: 2.968801293373108\n",
            "{'acc': np.float64(0.1308876179848391), 'precision': np.float64(0.9990780011062144), 'recall': np.float64(0.1265976587143929), 'f1': np.float64(0.224720032981612), 'fpr': np.float64(0.0230414746542717), 'tp': 5418, 'tn': 212, 'fp': 5, 'fn': 37379}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============ 1. 读数据 + 拆 benign-only ============\n",
        "def load_csv_expanded(path):\n",
        "    df = pd.read_csv(path)\n",
        "    seq_cols = [c for c in df.columns if c.startswith(\"t_\")]\n",
        "    seqs = df[seq_cols].values.astype(int)      # shape: [N, 100]\n",
        "    labels = df[\"malware\"].values.astype(int)   # 1=malware, 0=benign\n",
        "    return seqs, labels\n",
        "\n",
        "def split_benign_only(seqs, labels, seed=42):\n",
        "    benign = seqs[labels == 0]\n",
        "    malware = seqs[labels == 1]\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.permutation(len(benign))\n",
        "\n",
        "    n = len(benign)\n",
        "    n_train = int(0.7*n)\n",
        "    n_val   = int(0.1*n)\n",
        "\n",
        "    train = benign[idx[:n_train]]\n",
        "    val   = benign[idx[n_train:n_train+n_val]]\n",
        "    test_benign = benign[idx[n_train+n_val:]]\n",
        "    test_malware = malware\n",
        "    return train, val, test_benign, test_malware\n",
        "\n",
        "# ============ 2. 滑动窗口 ============\n",
        "def make_windows(seqs, window_size=10):\n",
        "    X, y = [], []\n",
        "    for s in seqs:\n",
        "        s = s.tolist()\n",
        "        for i in range(len(s) - window_size):\n",
        "            X.append(s[i:i+window_size])\n",
        "            y.append(s[i+window_size])\n",
        "    return np.array(X, dtype=int), np.array(y, dtype=int)\n",
        "\n",
        "# ============ 3. Dataset ============\n",
        "class WindowDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "# ============ 4. LSTM LM ============\n",
        "class LSTMLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "            dropout=dropout if num_layers>1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.emb(x)        # [B, W, E]\n",
        "        o, _ = self.lstm(e)    # [B, W, H]\n",
        "        last = o[:, -1, :]\n",
        "        return self.fc(last)   # [B, V]\n",
        "\n",
        "# ============ 5. 训练/验证 ============\n",
        "def eval_loss(model, loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            total += crit(model(Xb), yb).item()\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=40, lr=1e-3, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val, best_state = 1e9, None\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for Xb, yb in tqdm(train_loader, desc=f\"Epoch {ep}\"):\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = crit(model(Xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.item() * Xb.size(0)\n",
        "\n",
        "        val_loss = eval_loss(model, val_loader, device)\n",
        "        print(f\"ep{ep}: train={total/len(train_loader.dataset):.4f}, val={val_loss:.4f}\")\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "# ============ 6. 序列 NLL 异常分数 ============\n",
        "def sequence_scores_nll(model, seqs, window_size=10, device=\"cuda\"):#score 越大 = 越不符合 benign 模式 = 越可疑\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    model.eval()\n",
        "    scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for s in seqs:\n",
        "            X, y = make_windows([s], window_size)\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            y = torch.tensor(y, dtype=torch.long).to(device)\n",
        "            nll = crit(model(X), y)\n",
        "            scores.append(nll.mean().item())\n",
        "    return np.array(scores)\n",
        "\n",
        "def pick_threshold(val_scores, q=0.99):#在验证集上，大约 99% 的 benign score 都 低于 这个阈值\n",
        "    return float(np.quantile(val_scores, q))\n",
        "\n",
        "def evaluate(th, benign_scores, malware_scores):\n",
        "    y_true = np.array([0]*len(benign_scores) + [1]*len(malware_scores))\n",
        "    y_pred = np.array(\n",
        "        [1 if s>th else 0 for s in benign_scores] +\n",
        "        [1 if s>th else 0 for s in malware_scores]\n",
        "    )\n",
        "    tp = ((y_true==1)&(y_pred==1)).sum()\n",
        "    tn = ((y_true==0)&(y_pred==0)).sum()\n",
        "    fp = ((y_true==0)&(y_pred==1)).sum()\n",
        "    fn = ((y_true==1)&(y_pred==0)).sum()\n",
        "\n",
        "    precision = tp/(tp+fp+1e-9)\n",
        "    recall    = tp/(tp+fn+1e-9)\n",
        "    f1        = 2*precision*recall/(precision+recall+1e-9)\n",
        "    acc       = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "    fpr       = fp/(fp+tn+1e-9)\n",
        "    return dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "\n",
        "# ============ 7. 主流程 ============\n",
        "def main():\n",
        "    path = \"./dynamic_api_call_sequence_per_malware_100_0_306.csv\"\n",
        "    seqs, labels = load_csv_expanded(path)\n",
        "    train, val, test_benign, test_malware = split_benign_only(seqs, labels)\n",
        "\n",
        "    # vocab_size 需要从 token 最大值推出来（+1，因为从0计数）\n",
        "    vocab_size = int(seqs.max()) + 1\n",
        "    print(\"vocab_size:\", vocab_size)\n",
        "\n",
        "    window_size = 20\n",
        "    Xtr, ytr = make_windows(train, window_size)\n",
        "    Xva, yva = make_windows(val, window_size)\n",
        "\n",
        "    train_loader = DataLoader(WindowDataset(Xtr, ytr), batch_size=256, shuffle=True)\n",
        "    val_loader   = DataLoader(WindowDataset(Xva, yva), batch_size=256)\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = LSTMLM(vocab_size=vocab_size)\n",
        "    model = train_model(model, train_loader, val_loader, device=device)\n",
        "\n",
        "    val_scores = sequence_scores_nll(model, val, window_size, device=device)\n",
        "    th = pick_threshold(val_scores, q=0.99)\n",
        "    print(\"threshold:\", th)\n",
        "\n",
        "    benign_scores  = sequence_scores_nll(model, test_benign, window_size, device=device)\n",
        "    malware_scores = sequence_scores_nll(model, test_malware, window_size, device=device)\n",
        "    metrics = evaluate(th, benign_scores, malware_scores)\n",
        "\n",
        "    print(metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}