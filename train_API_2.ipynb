{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjNg5WgXZ4Uzk9ngxP0H7B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynameislllyt/API_Experiment/blob/main/train_API_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1、FP 较高（误报偏多）模型对异常很敏感\n",
        "Confusion matrix (行=真实  列=预测):\n",
        "[[ 1060  4330]\n",
        " [ 1664 23391]]\n",
        "Precision=0.8438, Recall=0.9336, F1=0.8864\n",
        "(Top-k = 5)"
      ],
      "metadata": {
        "id": "eIEpaveB5rXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cKNuJlMV28w5",
        "outputId": "732a0578-6cdd-4867-c628-c77ef410dfc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-25 11:53:47--  https://raw.githubusercontent.com/thpablo/Notebook_KNN_CSIC_Data/main/csicFinal.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21147547 (20M) [text/plain]\n",
            "Saving to: ‘csicFinal.csv’\n",
            "\n",
            "csicFinal.csv       100%[===================>]  20.17M  53.6MB/s    in 0.4s    \n",
            "\n",
            "2025-11-25 11:53:48 (53.6 MB/s) - ‘csicFinal.csv’ saved [21147547/21147547]\n",
            "\n",
            "   Class Method                              URI Host-Header            Host  \\\n",
            "0  Valid    GET               /tienda1/index.jsp    HTTP/1.1  localhost:8080   \n",
            "1  Valid    GET      /tienda1/publico/anadir.jsp    HTTP/1.1  localhost:8080   \n",
            "2  Valid   POST      /tienda1/publico/anadir.jsp    HTTP/1.1  localhost:8080   \n",
            "3  Valid    GET  /tienda1/publico/autenticar.jsp    HTTP/1.1  localhost:8080   \n",
            "4  Valid   POST  /tienda1/publico/autenticar.jsp    HTTP/1.1  localhost:8080   \n",
            "\n",
            "  Connection                                             Accept  \\\n",
            "0      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "1      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "2      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "3      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "4      close  text/xml,application/xml,application/xhtml+xml...   \n",
            "\n",
            "                Accept-Charset Accept-Language Cache-control  \\\n",
            "0  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "1  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "2  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "3  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "4  utf-8, utf-8;q=0.5, *;q=0.5              en      no-cache   \n",
            "\n",
            "                                        Cookie    Pragma  Content-Length  \\\n",
            "0  JSESSIONID=EA414B3E327DED6875848530C864BD8F  no-cache             NaN   \n",
            "1  JSESSIONID=54E25FF4B7F0E4E855B112F882E9EEA5  no-cache             NaN   \n",
            "2  JSESSIONID=788887A0F479749C4CEEA1E268B4A501  no-cache            74.0   \n",
            "3  JSESSIONID=94ECD5EE8EF7EFE4BB26C701B150ED7B  no-cache             NaN   \n",
            "4  JSESSIONID=23391DBBADEC19FE01E02D201F278C6A  no-cache            60.0   \n",
            "\n",
            "                        Content-Type  \\\n",
            "0                                NaN   \n",
            "1                                NaN   \n",
            "2  application/x-www-form-urlencoded   \n",
            "3                                NaN   \n",
            "4  application/x-www-form-urlencoded   \n",
            "\n",
            "                                           POST-Data  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2  id=1&nombre=Jam%F3n+Ib%E9rico&precio=39&cantid...   \n",
            "3                                                NaN   \n",
            "4  modo=entrar&login=caria&pwd=egipciaca&remember...   \n",
            "\n",
            "                                           GET-Query  \n",
            "0                                                NaN  \n",
            "1  id=1&nombre=Jam%F3n+Ib%E9rico&precio=39&cantid...  \n",
            "2                                                NaN  \n",
            "3  modo=entrar&login=caria&pwd=egipciaca&remember...  \n",
            "4                                                NaN  \n",
            "Index(['Class', 'Method', 'URI', 'Host-Header', 'Host', 'Connection', 'Accept',\n",
            "       'Accept-Charset', 'Accept-Language', 'Cache-control', 'Cookie',\n",
            "       'Pragma', 'Content-Length', 'Content-Type', 'POST-Data', 'GET-Query'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# 在 Colab 中下载 csicFinal.csv （基于 CSIC 2010）\n",
        "!wget -O csicFinal.csv https://raw.githubusercontent.com/thpablo/Notebook_KNN_CSIC_Data/main/csicFinal.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"csicFinal.csv\")\n",
        "print(df.head())\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1. 导入库 & 读取数据\n",
        "# ===========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# 如果是在 Colab，可以用相对路径（假设已经 wget 下来了）\n",
        "CSV_PATH = \"csicFinal.csv\"   # 按你实际路径改\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"数据维度:\", df.shape)\n",
        "print(\"列名:\", df.columns.tolist())\n",
        "\n",
        "print(\"\\nClass 列取值统计：\")\n",
        "print(df[\"Class\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AddvKTJJ3X_g",
        "outputId": "e252cd7f-2ffe-4832-ba5f-c5df101ef806"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据维度: (61065, 16)\n",
            "列名: ['Class', 'Method', 'URI', 'Host-Header', 'Host', 'Connection', 'Accept', 'Accept-Charset', 'Accept-Language', 'Cache-control', 'Cookie', 'Pragma', 'Content-Length', 'Content-Type', 'POST-Data', 'GET-Query']\n",
            "\n",
            "Class 列取值统计：\n",
            "Class\n",
            "Valid        36000\n",
            "Anomalous    25065\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2. 划分正常 / 异常 & 数据集\n",
        "# ===========================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "LABEL_COL = \"Class\"\n",
        "\n",
        "# 假设 normal 是样本最多的那个类别（一般就是 \"normal\"）\n",
        "normal_label = df[LABEL_COL].value_counts().idxmax()\n",
        "print(\"推测正常标签为:\", normal_label)\n",
        "\n",
        "normal_df   = df[df[LABEL_COL] == normal_label].copy()\n",
        "abnormal_df = df[df[LABEL_COL] != normal_label].copy()\n",
        "\n",
        "print(\"normal 样本数:\", len(normal_df))\n",
        "print(\"abnormal 样本数:\", len(abnormal_df))\n",
        "\n",
        "# 在 normal 中划分 train / val / test_normal\n",
        "train_norm, temp_norm = train_test_split(\n",
        "    normal_df, test_size=0.3, random_state=42, shuffle=True\n",
        ")\n",
        "val_norm, test_norm = train_test_split(\n",
        "    temp_norm, test_size=0.5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# 异常全部做 test_abn\n",
        "test_abn = abnormal_df\n",
        "\n",
        "print(\"train_norm:\", len(train_norm))\n",
        "print(\"val_norm  :\", len(val_norm))\n",
        "print(\"test_norm :\", len(test_norm))\n",
        "print(\"test_abn  :\", len(test_abn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTeyPn9k3dbz",
        "outputId": "04575fbd-9396-49b6-a8d7-03453ef649e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "推测正常标签为: Valid\n",
            "normal 样本数: 36000\n",
            "abnormal 样本数: 25065\n",
            "train_norm: 25200\n",
            "val_norm  : 5400\n",
            "test_norm : 5400\n",
            "test_abn  : 25065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3. 事件抽象函数（Method + URI 模板）\n",
        "# ===========================\n",
        "def template_uri(uri: str) -> str:\n",
        "    \"\"\"\n",
        "    把 URI 归一化：\n",
        "    - 去掉 query (? 后面)\n",
        "    - 把数字替换成 <num>\n",
        "    \"\"\"\n",
        "    if pd.isna(uri):\n",
        "        uri = \"\"\n",
        "    uri = str(uri)\n",
        "\n",
        "    # 去掉 query\n",
        "    if \"?\" in uri:\n",
        "        uri = uri.split(\"?\", 1)[0]\n",
        "\n",
        "    # 把连续数字替换为 <num>\n",
        "    uri = re.sub(r\"\\d+\", \"<num>\", uri)\n",
        "\n",
        "    return uri\n",
        "\n",
        "def row_to_event_str(row) -> str:\n",
        "    method = str(row.get(\"Method\", \"\")).upper()\n",
        "    uri_raw = row.get(\"URI\", \"\")\n",
        "    uri_t = template_uri(uri_raw)\n",
        "    event_str = f\"{method}|{uri_t}\"\n",
        "    return event_str\n",
        "\n",
        "# 看看示例\n",
        "print(\"\\n示例事件：\")\n",
        "for i in range(5):\n",
        "    print(row_to_event_str(df.iloc[i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Geat_s-T3gFI",
        "outputId": "032c87d7-336e-46f5-fb2c-c172e0ea2e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "示例事件：\n",
            "GET|/tienda<num>/index.jsp\n",
            "GET|/tienda<num>/publico/anadir.jsp\n",
            "POST|/tienda<num>/publico/anadir.jsp\n",
            "GET|/tienda<num>/publico/autenticar.jsp\n",
            "POST|/tienda<num>/publico/autenticar.jsp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 4. 构建事件字典（vocab）\n",
        "# ===========================\n",
        "# 只用 train_norm 中的事件来建词表\n",
        "train_events_str = [row_to_event_str(row) for _, row in train_norm.iterrows()]\n",
        "\n",
        "counter = Counter(train_events_str)\n",
        "print(\"\\n不同事件个数(训练集):\", len(counter))\n",
        "\n",
        "# 预留特殊 token\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "event2id = {\n",
        "    PAD_TOKEN: 0,\n",
        "    UNK_TOKEN: 1,\n",
        "}\n",
        "id2event = {\n",
        "    0: PAD_TOKEN,\n",
        "    1: UNK_TOKEN,\n",
        "}\n",
        "\n",
        "for ev in counter:\n",
        "    idx = len(event2id)\n",
        "    event2id[ev] = idx\n",
        "    id2event[idx] = ev\n",
        "\n",
        "vocab_size = len(event2id)\n",
        "print(\"事件字典大小（含 PAD/UNK）:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQJITPs3kL-",
        "outputId": "452e891a-70ef-4f26-d211-3455bf8501d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "不同事件个数(训练集): 34\n",
            "事件字典大小（含 PAD/UNK）: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5. DataFrame → 事件 ID 序列\n",
        "# ===========================\n",
        "def df_to_event_ids(df_in, event2id):\n",
        "    ids = []\n",
        "    for _, row in df_in.iterrows():\n",
        "        ev_str = row_to_event_str(row)\n",
        "        ev_id = event2id.get(ev_str, event2id[UNK_TOKEN])\n",
        "        ids.append(ev_id)\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "train_ids = df_to_event_ids(train_norm, event2id)\n",
        "val_ids   = df_to_event_ids(val_norm,   event2id)\n",
        "test_norm_ids = df_to_event_ids(test_norm, event2id)\n",
        "test_abn_ids  = df_to_event_ids(test_abn,  event2id)\n",
        "\n",
        "print(\"train_ids shape:\", train_ids.shape)\n",
        "print(\"val_ids   shape:\", val_ids.shape)\n",
        "print(\"test_norm_ids shape:\", test_norm_ids.shape)\n",
        "print(\"test_abn_ids  shape:\", test_abn_ids.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkNv4YhO3oOB",
        "outputId": "6fddc2fe-6b3b-4c98-fcde-fb366dcb5c49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_ids shape: (25200,)\n",
            "val_ids   shape: (5400,)\n",
            "test_norm_ids shape: (5400,)\n",
            "test_abn_ids  shape: (25065,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 6. 滑动窗口 Dataset\n",
        "# ===========================\n",
        "class EventWindowDataset(Dataset):\n",
        "    \"\"\"\n",
        "    input:  长度为 L 的事件 ID 序列\n",
        "    target: 第 L+1 个事件 ID\n",
        "    （训练、验证时 label=None；测试时可带上 0/1 标签）\n",
        "    \"\"\"\n",
        "    def __init__(self, event_ids: np.ndarray, window_size: int, label: int = None):\n",
        "        self.window_size = window_size\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "        labels = []\n",
        "\n",
        "        N = len(event_ids)\n",
        "        for i in range(N - window_size):\n",
        "            X_list.append(event_ids[i:i+window_size])\n",
        "            y_list.append(event_ids[i+window_size])\n",
        "            if label is not None:\n",
        "                labels.append(label)\n",
        "\n",
        "        self.X = torch.tensor(np.stack(X_list), dtype=torch.long)\n",
        "        self.y = torch.tensor(np.array(y_list), dtype=torch.long)\n",
        "        self.has_label = label is not None\n",
        "        if self.has_label:\n",
        "            self.labels = torch.tensor(np.array(labels), dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.has_label:\n",
        "            return self.X[idx], self.y[idx], self.labels[idx]\n",
        "        else:\n",
        "            return self.X[idx], self.y[idx]\n",
        "\n",
        "window_size = 10\n",
        "\n",
        "train_dataset = EventWindowDataset(train_ids, window_size=window_size, label=None)\n",
        "val_dataset   = EventWindowDataset(val_ids,   window_size=window_size, label=None)\n",
        "\n",
        "print(\"train windows:\", len(train_dataset))\n",
        "print(\"val windows  :\", len(val_dataset))\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6JI5iN-3snJ",
        "outputId": "716611f6-1180-443f-fd05-f3fad69fc0a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train windows: 25190\n",
            "val windows  : 5390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 7. DeepLog 风格 LSTM 模型\n",
        "# ===========================\n",
        "class DeepLogLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [B, L] 事件 ID 序列\n",
        "        return: logits [B, vocab_size]，对应下一个事件的概率分布（未 softmax）\n",
        "        \"\"\"\n",
        "        emb = self.embedding(x)           # [B, L, emb]\n",
        "        out, _ = self.lstm(emb)           # [B, L, hidden]\n",
        "        last_h = out[:, -1, :]            # [B, hidden]\n",
        "        logits = self.fc(last_h)          # [B, vocab_size]\n",
        "        return logits\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = DeepLogLSTM(vocab_size=vocab_size, embedding_dim=64, hidden_size=64, num_layers=1)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"模型参数量:\", total_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlJtbUGf3t_J",
        "outputId": "854bb4a0-7665-4a24-86b5-7c38cec1357d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "模型参数量: 37924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 8. 训练 & 验证\n",
        "# ===========================\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        logits = model(X_batch)          # [B, vocab_size]\n",
        "        loss = criterion(logits, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * X_batch.size(0)\n",
        "    return total_loss / len(train_dataset)\n",
        "\n",
        "def eval_one_epoch():\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_loss += loss.item() * X_batch.size(0)\n",
        "    return total_loss / len(val_dataset)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch()\n",
        "    val_loss = eval_one_epoch()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MxGPDud33h-",
        "outputId": "2e372ba2-6006-40e2-95b8-5a4c6f32c9d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - train_loss=3.529273, val_loss=3.509246\n",
            "Epoch 2/10 - train_loss=3.492899, val_loss=3.506516\n",
            "Epoch 3/10 - train_loss=3.485915, val_loss=3.507505\n",
            "Epoch 4/10 - train_loss=3.479956, val_loss=3.512433\n",
            "Epoch 5/10 - train_loss=3.474415, val_loss=3.511867\n",
            "Epoch 6/10 - train_loss=3.468172, val_loss=3.516045\n",
            "Epoch 7/10 - train_loss=3.461126, val_loss=3.518617\n",
            "Epoch 8/10 - train_loss=3.453674, val_loss=3.522980\n",
            "Epoch 9/10 - train_loss=3.445647, val_loss=3.527018\n",
            "Epoch 10/10 - train_loss=3.435652, val_loss=3.534277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 9. 测试集窗口（正常=0 / 异常=1）\n",
        "# ===========================\n",
        "test_norm_dataset = EventWindowDataset(test_norm_ids, window_size=window_size, label=0)\n",
        "test_abn_dataset  = EventWindowDataset(test_abn_ids,  window_size=window_size, label=1)\n",
        "\n",
        "# 合并两个测试集\n",
        "test_X = torch.cat([test_norm_dataset.X, test_abn_dataset.X], dim=0)\n",
        "test_y_next = torch.cat([test_norm_dataset.y, test_abn_dataset.y], dim=0)\n",
        "test_labels = torch.cat([test_norm_dataset.labels, test_abn_dataset.labels], dim=0)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(test_X, test_y_next, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "print(\"test windows:\", len(test_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaxGXlbP4cbZ",
        "outputId": "17272dbb-e6e6-4bc1-9739-5fc31db11299"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test windows: 30445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 10. DeepLog Top-k 异常检测 & 指标\n",
        "# ===========================\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "k = 5  # Top-k\n",
        "\n",
        "all_true_labels = []\n",
        "all_pred_labels = []  # 0 正常, 1 异常\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_next_batch, label_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_next_batch = y_next_batch.to(device)   # 真实下一事件 ID\n",
        "        label_batch = label_batch.to(device)     # 0/1\n",
        "\n",
        "        logits = model(X_batch)                  # [B, vocab_size]\n",
        "        # 取 top-k\n",
        "        topk_probs, topk_indices = torch.topk(F.softmax(logits, dim=1), k=k, dim=1)\n",
        "        # 对于每个样本，判断真实 y_next 是否在 top-k 里\n",
        "        # bool tensor: True 表示 \"在 top-k 内\" -> 正常; False -> 异常\n",
        "        in_topk = (topk_indices == y_next_batch.unsqueeze(1)).any(dim=1)\n",
        "\n",
        "        # DeepLog 规则：不在 top-k → 异常\n",
        "        pred_is_anomaly = (~in_topk).long()   # 1 异常, 0 正常\n",
        "\n",
        "        all_true_labels.append(label_batch.cpu().numpy())\n",
        "        all_pred_labels.append(pred_is_anomaly.cpu().numpy())\n",
        "\n",
        "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
        "all_pred_labels = np.concatenate(all_pred_labels, axis=0)\n",
        "\n",
        "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "p, r, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='binary')\n",
        "\n",
        "print(\"Confusion matrix (行=真实  列=预测):\")\n",
        "print(cm)\n",
        "print(f\"Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "print(f\"(Top-k = {k})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJrAsGm04gMq",
        "outputId": "fc850bc8-4a26-497e-a5be-9e447c38b959"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (行=真实  列=预测):\n",
            "[[ 1060  4330]\n",
            " [ 1664 23391]]\n",
            "Precision=0.8438, Recall=0.9336, F1=0.8864\n",
            "(Top-k = 5)\n"
          ]
        }
      ]
    }
  ]
}