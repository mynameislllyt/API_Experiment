{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNn2VihelQ0ApY2kJWfGZmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynameislllyt/API_Experiment/blob/main/baseline4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoB8agpSlq7B",
        "outputId": "81167e0f-eeae-4e0f-de1f-c6d0cf96763d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_size: 307\n",
            "\n",
            "======================================================================\n",
            "实验1: 原始Baseline - 单窗口LSTM\n",
            "======================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 236/236 [00:03<00:00, 62.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.2689, val=1.4963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 236/236 [00:02<00:00, 86.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.1903, val=1.1313\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 236/236 [00:02<00:00, 87.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.9224, val=0.9654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 236/236 [00:02<00:00, 87.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.7713, val=0.8740\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 236/236 [00:02<00:00, 79.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6679, val=0.8374\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 236/236 [00:02<00:00, 84.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.5917, val=0.7948\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 236/236 [00:02<00:00, 85.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5270, val=0.7845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 236/236 [00:02<00:00, 85.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.4738, val=0.7647\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 236/236 [00:02<00:00, 79.73it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4279, val=0.7606\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 236/236 [00:03<00:00, 75.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.3919, val=0.7570\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 236/236 [00:02<00:00, 79.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3555, val=0.7519\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 236/236 [00:02<00:00, 83.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3253, val=0.7656\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 236/236 [00:03<00:00, 76.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.2999, val=0.7768\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 236/236 [00:02<00:00, 82.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.2765, val=0.7853\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 236/236 [00:02<00:00, 82.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2522, val=0.8025\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16: 100%|██████████| 236/236 [00:02<00:00, 82.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep16: train=0.2339, val=0.8129\n",
            "Early stop at epoch 16\n",
            "\n",
            "【Baseline结果】\n",
            "Threshold: 2.5218\n",
            "Test Metrics: {'acc': np.float64(0.30753156290813216), 'precision': np.float64(0.9987506006726574), 'recall': np.float64(0.30352240200945435), 'f1': np.float64(0.46556010985012836), 'fpr': np.float64(0.059907834101106415), 'tp': 10392, 'tn': 204, 'fp': 13, 'fn': 23846}\n",
            "\n",
            "======================================================================\n",
            "实验2: 记忆增强LSTM (创新点1)\n",
            "======================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 236/236 [00:02<00:00, 80.59it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.3860, val=1.5758\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 236/236 [00:02<00:00, 80.82it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.2631, val=1.1487\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 236/236 [00:02<00:00, 83.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.9723, val=0.9725\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 236/236 [00:02<00:00, 84.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.8151, val=0.8957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 236/236 [00:02<00:00, 79.79it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.7091, val=0.8406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 236/236 [00:02<00:00, 81.70it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.6281, val=0.7948\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 236/236 [00:02<00:00, 84.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5648, val=0.7871\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 236/236 [00:02<00:00, 84.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.5099, val=0.7731\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 236/236 [00:02<00:00, 79.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4631, val=0.7579\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 236/236 [00:02<00:00, 82.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4216, val=0.7557\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 236/236 [00:02<00:00, 83.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3870, val=0.7536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 236/236 [00:02<00:00, 83.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3566, val=0.7520\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 236/236 [00:02<00:00, 79.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.3264, val=0.7558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 236/236 [00:02<00:00, 82.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.3026, val=0.7712\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 236/236 [00:02<00:00, 83.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2774, val=0.7609\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16: 100%|██████████| 236/236 [00:02<00:00, 83.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep16: train=0.2576, val=0.7853\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17: 100%|██████████| 236/236 [00:02<00:00, 78.68it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep17: train=0.2380, val=0.7997\n",
            "Early stop at epoch 17\n",
            "\n",
            "--- Alpha = 0.3 ---\n",
            "Threshold: 0.5996\n",
            "Test Metrics: {'acc': np.float64(0.29992744159047163), 'precision': np.float64(0.9946220788108933), 'recall': np.float64(0.2970967930369678), 'f1': np.float64(0.457528392763961), 'fpr': np.float64(0.2534562211969887), 'tp': 10172, 'tn': 162, 'fp': 55, 'fn': 24066}\n",
            "\n",
            "--- Alpha = 0.5 ---\n",
            "Threshold: 0.5905\n",
            "Test Metrics: {'acc': np.float64(0.3032361050645682), 'precision': np.float64(0.9946813654384493), 'recall': np.float64(0.3004264267772563), 'f1': np.float64(0.46147289046669243), 'fpr': np.float64(0.2534562211969887), 'tp': 10286, 'tn': 162, 'fp': 55, 'fn': 23952}\n",
            "\n",
            "--- Alpha = 0.7 ---\n",
            "Threshold: 0.6014\n",
            "Test Metrics: {'acc': np.float64(0.2997242780438166), 'precision': np.float64(0.9949089485019585), 'recall': np.float64(0.2968047199018548), 'f1': np.float64(0.4572122735594563), 'fpr': np.float64(0.23963133640442566), 'tp': 10162, 'tn': 165, 'fp': 52, 'fn': 24076}\n",
            "\n",
            "======================================================================\n",
            "实验3: 多窗口集成 (创新点2)\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training window_size=10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 266/266 [00:01<00:00, 137.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.1488, val=1.3812\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 266/266 [00:01<00:00, 147.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.1290, val=1.0636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 266/266 [00:01<00:00, 143.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.8824, val=0.9336\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 266/266 [00:01<00:00, 137.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.7446, val=0.8678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 266/266 [00:01<00:00, 147.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6541, val=0.8309\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 266/266 [00:01<00:00, 147.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.5815, val=0.8079\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 266/266 [00:01<00:00, 147.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5215, val=0.7906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 266/266 [00:01<00:00, 138.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.4749, val=0.7845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 266/266 [00:01<00:00, 142.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4307, val=0.7773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 266/266 [00:01<00:00, 137.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.3948, val=0.7808\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 266/266 [00:01<00:00, 147.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3620, val=0.7797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 266/266 [00:01<00:00, 147.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3326, val=0.7859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 266/266 [00:01<00:00, 147.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.3069, val=0.8044\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 266/266 [00:01<00:00, 147.72it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.2849, val=0.7914\n",
            "Early stop at epoch 14\n",
            "\n",
            "============================================================\n",
            "Training window_size=20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 236/236 [00:02<00:00, 82.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.2969, val=1.5103\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 236/236 [00:02<00:00, 84.68it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.2143, val=1.1380\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 236/236 [00:02<00:00, 80.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.9430, val=0.9648\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 236/236 [00:02<00:00, 84.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.7901, val=0.8813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 236/236 [00:02<00:00, 81.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6887, val=0.8473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 236/236 [00:02<00:00, 84.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.6059, val=0.8038\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 236/236 [00:02<00:00, 80.59it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5458, val=0.7911\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 236/236 [00:02<00:00, 84.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.4909, val=0.7792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 236/236 [00:02<00:00, 81.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4482, val=0.7767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 236/236 [00:02<00:00, 84.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4052, val=0.7608\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 236/236 [00:02<00:00, 80.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3722, val=0.7590\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 236/236 [00:02<00:00, 83.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3404, val=0.7658\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 236/236 [00:02<00:00, 81.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.3090, val=0.7728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 236/236 [00:02<00:00, 84.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.2866, val=0.7838\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 236/236 [00:02<00:00, 80.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2652, val=0.7859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16: 100%|██████████| 236/236 [00:02<00:00, 83.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep16: train=0.2445, val=0.7955\n",
            "Early stop at epoch 16\n",
            "\n",
            "============================================================\n",
            "Training window_size=30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 207/207 [00:03<00:00, 56.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.3926, val=1.5818\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 207/207 [00:03<00:00, 59.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.2480, val=1.1616\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 207/207 [00:03<00:00, 59.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.9642, val=1.0024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 207/207 [00:03<00:00, 57.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.7997, val=0.9123\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 207/207 [00:03<00:00, 57.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6932, val=0.8713\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 207/207 [00:03<00:00, 59.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.6105, val=0.8392\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 207/207 [00:03<00:00, 57.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5422, val=0.8153\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 207/207 [00:03<00:00, 59.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.4910, val=0.7983\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 207/207 [00:03<00:00, 59.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4457, val=0.7990\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 207/207 [00:03<00:00, 55.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4026, val=0.7803\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 207/207 [00:03<00:00, 59.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3659, val=0.7987\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 207/207 [00:03<00:00, 58.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3368, val=0.7929\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 207/207 [00:03<00:00, 57.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.3066, val=0.7926\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 207/207 [00:03<00:00, 57.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.2808, val=0.8150\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 207/207 [00:03<00:00, 59.12it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2583, val=0.8115\n",
            "Early stop at epoch 15\n",
            "\n",
            "--- Ensemble Method: vote ---\n",
            "Test Metrics: {'acc': np.float64(0.10657379190247841), 'precision': np.float64(0.9985569985567104), 'recall': np.float64(0.10105730474910624), 'f1': np.float64(0.18353977120405582), 'tp': 3460, 'tn': 212, 'fp': 5, 'fn': 30778}\n",
            "\n",
            "--- Ensemble Method: max ---\n",
            "Test Metrics: {'acc': np.float64(0.48759251197212344), 'precision': np.float64(0.99771895071727), 'recall': np.float64(0.48545475787135683), 'f1': np.float64(0.6531229734087657), 'tp': 16621, 'tn': 179, 'fp': 38, 'fn': 17617}\n",
            "\n",
            "======================================================================\n",
            "实验4: 记忆增强多窗口集成 (组合创新)\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training window_size=10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 266/266 [00:01<00:00, 138.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.1963, val=1.4330\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 266/266 [00:01<00:00, 147.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.1587, val=1.0812\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 266/266 [00:01<00:00, 146.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.9053, val=0.9479\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 266/266 [00:01<00:00, 137.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.7664, val=0.8779\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 266/266 [00:01<00:00, 145.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6687, val=0.8386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 266/266 [00:01<00:00, 137.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.5978, val=0.8103\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 266/266 [00:01<00:00, 138.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5364, val=0.7963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 266/266 [00:01<00:00, 136.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.4874, val=0.7881\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 266/266 [00:01<00:00, 147.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4421, val=0.7794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 266/266 [00:01<00:00, 147.68it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4042, val=0.7721\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 266/266 [00:01<00:00, 135.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3709, val=0.7795\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 266/266 [00:01<00:00, 136.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3428, val=0.7838\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 266/266 [00:01<00:00, 140.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.3178, val=0.7994\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 266/266 [00:01<00:00, 146.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.2924, val=0.8034\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 266/266 [00:01<00:00, 137.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2733, val=0.8122\n",
            "Early stop at epoch 15\n",
            "\n",
            "============================================================\n",
            "Training window_size=20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 236/236 [00:02<00:00, 80.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.2946, val=1.4995\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 236/236 [00:02<00:00, 81.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.2013, val=1.1211\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 236/236 [00:02<00:00, 84.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.9342, val=0.9697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 236/236 [00:02<00:00, 84.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.7844, val=0.8910\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 236/236 [00:02<00:00, 84.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6801, val=0.8476\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 236/236 [00:02<00:00, 81.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.6030, val=0.8134\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 236/236 [00:02<00:00, 84.12it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5401, val=0.7954\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 236/236 [00:02<00:00, 80.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.4848, val=0.7911\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 236/236 [00:02<00:00, 83.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4397, val=0.7697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 236/236 [00:02<00:00, 80.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4005, val=0.7764\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 236/236 [00:02<00:00, 83.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3680, val=0.7622\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 236/236 [00:02<00:00, 80.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3357, val=0.7861\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 236/236 [00:02<00:00, 83.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.3077, val=0.7840\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 236/236 [00:02<00:00, 81.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.2828, val=0.7938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 236/236 [00:02<00:00, 83.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2621, val=0.8124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16: 100%|██████████| 236/236 [00:02<00:00, 80.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep16: train=0.2426, val=0.8095\n",
            "Early stop at epoch 16\n",
            "\n",
            "============================================================\n",
            "Training window_size=30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 207/207 [00:03<00:00, 58.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.3464, val=1.5092\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 207/207 [00:03<00:00, 56.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep2: train=1.2018, val=1.1223\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 207/207 [00:03<00:00, 58.78it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep3: train=0.9287, val=0.9810\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 207/207 [00:03<00:00, 58.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep4: train=0.7788, val=0.8944\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 207/207 [00:03<00:00, 57.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6734, val=0.8573\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 207/207 [00:03<00:00, 58.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep6: train=0.5949, val=0.8216\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 207/207 [00:03<00:00, 56.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep7: train=0.5291, val=0.8017\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 207/207 [00:03<00:00, 57.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep8: train=0.4763, val=0.7873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 207/207 [00:03<00:00, 58.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep9: train=0.4332, val=0.7924\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 207/207 [00:03<00:00, 58.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.3947, val=0.7711\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 207/207 [00:03<00:00, 55.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep11: train=0.3573, val=0.7825\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 207/207 [00:03<00:00, 58.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep12: train=0.3291, val=0.7805\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 207/207 [00:03<00:00, 58.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep13: train=0.2998, val=0.7913\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 207/207 [00:03<00:00, 57.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep14: train=0.2752, val=0.7938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 207/207 [00:03<00:00, 58.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15: train=0.2536, val=0.8101\n",
            "Early stop at epoch 15\n",
            "\n",
            "--- Ensemble Method: vote ---\n",
            "Test Metrics: {'acc': np.float64(0.018778116383688325), 'precision': np.float64(0.995391705066831), 'recall': np.float64(0.012617559436882628), 'f1': np.float64(0.024919243168632185), 'tp': 432, 'tn': 215, 'fp': 2, 'fn': 33806}\n",
            "\n",
            "--- Ensemble Method: max ---\n",
            "Test Metrics: {'acc': np.float64(0.5046872732549557), 'precision': np.float64(0.996645071725995), 'recall': np.float64(0.50324201179974), 'f1': np.float64(0.6687885723134651), 'tp': 17230, 'tn': 159, 'fp': 58, 'fn': 17008}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============ 1. 读数据 + 拆 benign-only ============\n",
        "def load_csv_expanded(path):\n",
        "    df = pd.read_csv(path)\n",
        "    seq_cols = [c for c in df.columns if c.startswith(\"t_\")]\n",
        "    seqs = df[seq_cols].values.astype(int)      # shape: [N, 100]\n",
        "    labels = df[\"malware\"].values.astype(int)   # 1=malware, 0=benign\n",
        "    return seqs, labels\n",
        "\n",
        "def split_benign_only(seqs, labels, seed=42):\n",
        "    benign = seqs[labels == 0]\n",
        "    malware = seqs[labels == 1]\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx_b = rng.permutation(len(benign))\n",
        "    idx_m = rng.permutation(len(malware))\n",
        "\n",
        "    n_b = len(benign)\n",
        "    n_m = len(malware)\n",
        "\n",
        "    n_train = int(0.7*n_b)\n",
        "    n_val   = int(0.1*n_b)\n",
        "\n",
        "    benign_train = benign[idx_b[:n_train]]\n",
        "    benign_val   = benign[idx_b[n_train:n_train+n_val]]\n",
        "    benign_test  = benign[idx_b[n_train+n_val:]]\n",
        "\n",
        "    # 比如 20% malware 做 val，用来选阈值，剩下做 test\n",
        "    n_m_val = int(0.2*n_m)\n",
        "    malware_val  = malware[idx_m[:n_m_val]]\n",
        "    malware_test = malware[idx_m[n_m_val:]]\n",
        "\n",
        "    return benign_train, benign_val, benign_test, malware_val, malware_test\n",
        "\n",
        "# ============ 2. 滑动窗口 ============\n",
        "def make_windows(seqs, window_size=10):\n",
        "    X, y = [], []\n",
        "    for s in seqs:\n",
        "        s = s.tolist()\n",
        "        for i in range(len(s) - window_size):\n",
        "            X.append(s[i:i+window_size])\n",
        "            y.append(s[i+window_size])\n",
        "    return np.array(X, dtype=int), np.array(y, dtype=int)\n",
        "\n",
        "# ============ 3. Dataset ============\n",
        "class WindowDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "# ============ 4. LSTM LM ============\n",
        "class LSTMLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        # self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)  # 去掉 padding_idx\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "            dropout=dropout if num_layers>1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.emb(x)        # [B, W, E]\n",
        "        o, _ = self.lstm(e)    # [B, W, H]\n",
        "        last = o[:, -1, :]\n",
        "        return self.fc(last)   # [B, V]\n",
        "\n",
        "# ============ 【新增】4.5. 记忆增强LSTM ============\n",
        "class MemoryAugmentedLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, num_layers=2,\n",
        "                 dropout=0.3, memory_size=1000):\n",
        "        super().__init__()\n",
        "        # 复用原有的LSTM LM结构\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "            dropout=dropout if num_layers>1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "        # 新增：记忆库\n",
        "        self.register_buffer('memory_bank', torch.zeros(memory_size, hidden_dim))\n",
        "        self.memory_ptr = 0\n",
        "        self.memory_size = memory_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, return_hidden=False):\n",
        "        \"\"\"前向传播，可选返回hidden state\"\"\"\n",
        "        e = self.emb(x)        # [B, W, E]\n",
        "        o, (h, c) = self.lstm(e)    # h: [num_layers, B, H]\n",
        "        logits = self.fc(o[:, -1, :])   # [B, V]\n",
        "\n",
        "        if return_hidden:\n",
        "            return logits, h[-1]  # 返回最后一层的hidden\n",
        "        return logits\n",
        "\n",
        "    def update_memory(self, hidden_states):\n",
        "        \"\"\"训练时更新记忆库\"\"\"\n",
        "        with torch.no_grad():\n",
        "            batch_size = hidden_states.size(0)\n",
        "            ptr = self.memory_ptr\n",
        "\n",
        "            if ptr + batch_size <= self.memory_size:\n",
        "                self.memory_bank[ptr:ptr+batch_size] = hidden_states.detach()\n",
        "                self.memory_ptr = (ptr + batch_size) % self.memory_size\n",
        "            else:\n",
        "                remain = self.memory_size - ptr\n",
        "                self.memory_bank[ptr:] = hidden_states[:remain].detach()\n",
        "                self.memory_bank[:batch_size-remain] = hidden_states[remain:].detach()\n",
        "                self.memory_ptr = batch_size - remain\n",
        "\n",
        "    def compute_memory_distance(self, hidden_state):\n",
        "        \"\"\"计算与记忆库的距离\"\"\"\n",
        "        # hidden_state: [B, H]\n",
        "        distances = torch.cdist(hidden_state, self.memory_bank)  # [B, M]\n",
        "        k = min(50, self.memory_size)\n",
        "        min_distances, _ = torch.topk(distances, k, largest=False, dim=1)\n",
        "        return min_distances.mean(dim=1)  # [B]\n",
        "\n",
        "# ============ 5. 训练/验证 ============\n",
        "def eval_loss(model, loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            total += crit(model(Xb), yb).item()\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=20, lr=1e-3, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    #opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val, best_state = 1e9, None\n",
        "    patience, bad_count = 5, 0\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for Xb, yb in tqdm(train_loader, desc=f\"Epoch {ep}\"):\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = crit(model(Xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.item() * Xb.size(0)\n",
        "\n",
        "        val_loss = eval_loss(model, val_loader, device)\n",
        "        print(f\"ep{ep}: train={total/len(train_loader.dataset):.4f}, val={val_loss:.4f}\")\n",
        "        # if val_loss < best_val:\n",
        "        #     best_val = val_loss\n",
        "        #     best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "            bad_count = 0\n",
        "        else:\n",
        "            bad_count += 1\n",
        "            if bad_count >= patience:\n",
        "                print(f\"Early stop at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "# ============ 【修改】5.5. 训练记忆增强模型 ============\n",
        "def train_model_with_memory(model, train_loader, val_loader, epochs=20, lr=1e-3, device=\"cuda\"):\n",
        "    \"\"\"训练记忆增强模型，在训练过程中更新记忆库\"\"\"\n",
        "    \"\"\"\n",
        "    在 LSTMLM 的基础上加一个“隐状态记忆库 (memory_bank)”：\n",
        "      - 训练时，把 benign 的 hidden state 持续写入 memory_bank\n",
        "      - 检测时，根据当前样本 hidden 与记忆库中向量的距离，衡量“是否偏离正常模式”\n",
        "      - 最终异常分数 = 语言模型 NLL + 记忆距离 的组合\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val, best_state = 1e9, None\n",
        "    patience, bad_count = 5, 0\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for Xb, yb in tqdm(train_loader, desc=f\"Epoch {ep}\"):\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # 获取logits和hidden states\n",
        "            logits, hidden = model(Xb, return_hidden=True)\n",
        "            loss = crit(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.item() * Xb.size(0)\n",
        "\n",
        "            # 【关键】更新记忆库\n",
        "            model.update_memory(hidden)\n",
        "\n",
        "        val_loss = eval_loss_memory(model, val_loader, device)\n",
        "        print(f\"ep{ep}: train={total/len(train_loader.dataset):.4f}, val={val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "            bad_count = 0\n",
        "        else:\n",
        "            bad_count += 1\n",
        "            if bad_count >= patience:\n",
        "                print(f\"Early stop at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "def eval_loss_memory(model, loader, device=\"cuda\"):\n",
        "    \"\"\"验证记忆增强模型\"\"\"\n",
        "    model.eval()\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            logits = model(Xb, return_hidden=False)\n",
        "            total += crit(logits, yb).item()\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "# ============ 6. 序列 NLL 异常分数 ============\n",
        "def sequence_scores_nll(model, seqs, window_size=10, device=\"cuda\"):#score 越大 = 越不符合 benign 模式 = 越可疑\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    model.eval()\n",
        "    scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for s in seqs:\n",
        "            X, y = make_windows([s], window_size)\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            y = torch.tensor(y, dtype=torch.long).to(device)\n",
        "            nll = crit(model(X), y)\n",
        "            scores.append(nll.mean().item())\n",
        "    return np.array(scores)\n",
        "\n",
        "def search_best_threshold(benign_scores, malware_scores):\n",
        "    all_scores = np.concatenate([benign_scores, malware_scores])\n",
        "    cand_th = np.quantile(all_scores, np.linspace(0.7, 0.99, 20))  # 可以调范围\n",
        "\n",
        "    best_f1, best_th, best_metrics = -1, None, None\n",
        "    for th in cand_th:\n",
        "        m = evaluate(th, benign_scores, malware_scores)\n",
        "        if m[\"f1\"] > best_f1:\n",
        "            best_f1, best_th, best_metrics = m[\"f1\"], th, m\n",
        "    return best_th, best_metrics\n",
        "\n",
        "def pick_threshold(val_scores, q=0.99):#在验证集上，大约 99% 的 benign score 都 低于 这个阈值\n",
        "    return float(np.quantile(val_scores, q))\n",
        "\n",
        "def evaluate(th, benign_scores, malware_scores):\n",
        "    y_true = np.array([0]*len(benign_scores) + [1]*len(malware_scores))\n",
        "    y_pred = np.array(\n",
        "        [1 if s>th else 0 for s in benign_scores] +\n",
        "        [1 if s>th else 0 for s in malware_scores]\n",
        "    )\n",
        "    tp = ((y_true==1)&(y_pred==1)).sum()\n",
        "    tn = ((y_true==0)&(y_pred==0)).sum()\n",
        "    fp = ((y_true==0)&(y_pred==1)).sum()\n",
        "    fn = ((y_true==1)&(y_pred==0)).sum()\n",
        "\n",
        "    precision = tp/(tp+fp+1e-9)\n",
        "    recall    = tp/(tp+fn+1e-9)\n",
        "    f1        = 2*precision*recall/(precision+recall+1e-9)\n",
        "    acc       = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "    fpr       = fp/(fp+tn+1e-9)\n",
        "    return dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "\n",
        "# ============ 【新增】6.5. 混合异常分数（NLL + Memory Distance）============\n",
        "def sequence_scores_hybrid(model, seqs, window_size=10, alpha=0.5, device=\"cuda\"):\n",
        "    \"\"\"计算混合异常分数：NLL + 记忆距离\"\"\"\n",
        "    \"\"\"\n",
        "    对每条序列同时计算：\n",
        "      - NLL 分数（语言模型下一个 token 的平均负对数似然）\n",
        "      - Memory Distance 分数（hidden state 与记忆库中向量的距离）\n",
        "\n",
        "    然后做标准化 + 加权求和：\n",
        "      hybrid_score = alpha * NLL_norm + (1-alpha) * Mem_norm\n",
        "    \"\"\"\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    model.eval()\n",
        "    nll_scores = []\n",
        "    mem_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for s in seqs:\n",
        "            X, y = make_windows([s], window_size)\n",
        "            if len(X) == 0:  # 处理序列太短的情况\n",
        "                nll_scores.append(0.0)\n",
        "                mem_scores.append(0.0)\n",
        "                continue\n",
        "\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            y = torch.tensor(y, dtype=torch.long).to(device)\n",
        "\n",
        "            # 1. NLL分数\n",
        "            logits, hidden = model(X, return_hidden=True)\n",
        "            nll = crit(logits, y).mean().item()\n",
        "            nll_scores.append(nll)\n",
        "\n",
        "            # 2. 记忆距离分数\n",
        "            mem_dist = model.compute_memory_distance(hidden).mean().item()\n",
        "            mem_scores.append(mem_dist)\n",
        "\n",
        "    # 归一化后加权融合\n",
        "    nll_scores = np.array(nll_scores)\n",
        "    mem_scores = np.array(mem_scores)\n",
        "\n",
        "    nll_norm = (nll_scores - nll_scores.mean()) / (nll_scores.std() + 1e-8)\n",
        "    mem_norm = (mem_scores - mem_scores.mean()) / (mem_scores.std() + 1e-8)\n",
        "\n",
        "    hybrid_scores = alpha * nll_norm + (1 - alpha) * mem_norm\n",
        "    return hybrid_scores\n",
        "\n",
        "# ============ 【新增】7. 多窗口集成 ============\n",
        "class MultiWindowEnsemble:\n",
        "  \"\"\"\n",
        "    多窗口集成器：\n",
        "      - 为多个 window_size 各自训练一个模型（可以是普通 LSTM 或 Memory-Augmented LSTM）\n",
        "      - 对同一条序列，用多个窗口尺度分别打分+判决\n",
        "      - 通过投票 / 最大分数等策略做集成，提升鲁棒性\n",
        "    \"\"\"\n",
        "    def __init__(self, window_sizes=[10, 20, 30], vocab_size=307, use_memory=False):\n",
        "        self.window_sizes = window_sizes\n",
        "        self.vocab_size = vocab_size\n",
        "        self.use_memory = use_memory\n",
        "        self.models = {}\n",
        "        self.thresholds = {}\n",
        "\n",
        "    def train_all(self, benign_train, benign_val, device=\"cuda\"):\n",
        "        \"\"\"为每个窗口大小训练独立模型\"\"\"\n",
        "        for ws in self.window_sizes:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Training window_size={ws}\")\n",
        "\n",
        "            Xtr, ytr = make_windows(benign_train, ws)\n",
        "            Xva, yva = make_windows(benign_val, ws)\n",
        "\n",
        "            train_loader = DataLoader(WindowDataset(Xtr, ytr),\n",
        "                                     batch_size=256, shuffle=True)\n",
        "            val_loader = DataLoader(WindowDataset(Xva, yva), batch_size=256)\n",
        "\n",
        "            # 根据配置选择模型\n",
        "            if self.use_memory:\n",
        "                model = MemoryAugmentedLSTM(self.vocab_size, emb_dim=128,\n",
        "                                           hidden_dim=256, num_layers=2, dropout=0.3)\n",
        "                model = train_model_with_memory(model, train_loader, val_loader, device=device)\n",
        "            else:\n",
        "                model = LSTMLM(self.vocab_size, emb_dim=128,\n",
        "                              hidden_dim=256, num_layers=2, dropout=0.3)\n",
        "                model = train_model(model, train_loader, val_loader, device=device)\n",
        "\n",
        "            self.models[ws] = model\n",
        "\n",
        "            # 在验证集上确定阈值\n",
        "            if self.use_memory:\n",
        "                val_scores = sequence_scores_hybrid(model, benign_val, ws, alpha=0.6, device=device)\n",
        "            else:\n",
        "                val_scores = sequence_scores_nll(model, benign_val, ws, device)\n",
        "            self.thresholds[ws] = np.quantile(val_scores, 0.99)\n",
        "\n",
        "    def predict_ensemble(self, seqs, device=\"cuda\", method='vote'):\n",
        "        \"\"\"集成预测\"\"\"\n",
        "        \"\"\"\n",
        "        对一批序列做集成预测：\n",
        "          - method='vote'：各模型独立二分类，最后按多数投票\n",
        "          - method='max'：归一化各模型分数，取每个样本在各模型中的最大分数再判断\n",
        "        返回：\n",
        "          - final_pred: 最终的 0/1 预测\n",
        "          - all_scores: 每个窗口大小对应的原始分数字典\n",
        "        \"\"\"\n",
        "        all_predictions = {}\n",
        "        all_scores = {}\n",
        "\n",
        "        # 每个模型独立预测\n",
        "        for ws in self.window_sizes:\n",
        "            if self.use_memory:\n",
        "                scores = sequence_scores_hybrid(self.models[ws], seqs, ws,\n",
        "                                               alpha=0.6, device=device)\n",
        "            else:\n",
        "                scores = sequence_scores_nll(self.models[ws], seqs, ws, device)\n",
        "\n",
        "            predictions = (scores > self.thresholds[ws]).astype(int)\n",
        "            all_predictions[ws] = predictions\n",
        "            all_scores[ws] = scores\n",
        "\n",
        "        # 集成策略\n",
        "        if method == 'vote':\n",
        "            # 投票法\n",
        "            stacked = np.stack([all_predictions[ws] for ws in self.window_sizes])\n",
        "            final_pred = (stacked.sum(axis=0) > len(self.window_sizes) / 2).astype(int)\n",
        "\n",
        "        elif method == 'max':\n",
        "            # 最大分数法\n",
        "            normalized_scores = []\n",
        "            for ws in self.window_sizes:\n",
        "                scores = all_scores[ws]\n",
        "                norm_scores = (scores - scores.mean()) / (scores.std() + 1e-8)\n",
        "                normalized_scores.append(norm_scores)\n",
        "\n",
        "            max_scores = np.max(normalized_scores, axis=0)\n",
        "            threshold = 0  # 已归一化，0为中值\n",
        "            final_pred = (max_scores > threshold).astype(int)\n",
        "\n",
        "        return final_pred, all_scores\n",
        "# ============ 7. 主流程 ============\n",
        "def main():\n",
        "    path = \"./dynamic_api_call_sequence_per_malware_100_0_306.csv\"\n",
        "    seqs, labels = load_csv_expanded(path)\n",
        "    benign_train, benign_val, benign_test, malware_val, malware_test = split_benign_only(seqs, labels)\n",
        "\n",
        "    vocab_size = int(seqs.max()) + 1\n",
        "    print(\"vocab_size:\", vocab_size)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # ========== 实验1：原始Baseline（保留用于对比）==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验1: 原始Baseline - 单窗口LSTM\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    window_size = 20  # 选择表现最好的窗口\n",
        "    Xtr, ytr = make_windows(benign_train, window_size)\n",
        "    Xva, yva = make_windows(benign_val, window_size)\n",
        "\n",
        "    train_loader = DataLoader(WindowDataset(Xtr, ytr), batch_size=256, shuffle=True)\n",
        "    val_loader = DataLoader(WindowDataset(Xva, yva), batch_size=256)\n",
        "\n",
        "    model_baseline = LSTMLM(vocab_size, emb_dim=128, hidden_dim=256, num_layers=2, dropout=0.3)\n",
        "    model_baseline = train_model(model_baseline, train_loader, val_loader, device=device)\n",
        "\n",
        "    benign_val_scores = sequence_scores_nll(model_baseline, benign_val, window_size, device=device)\n",
        "    malware_val_scores = sequence_scores_nll(model_baseline, malware_val, window_size, device=device)\n",
        "    best_th_baseline, _ = search_best_threshold(benign_val_scores, malware_val_scores)\n",
        "\n",
        "    benign_test_scores = sequence_scores_nll(model_baseline, benign_test, window_size, device=device)\n",
        "    malware_test_scores = sequence_scores_nll(model_baseline, malware_test, window_size, device=device)\n",
        "    metrics_baseline = evaluate(best_th_baseline, benign_test_scores, malware_test_scores)\n",
        "\n",
        "    print(f\"\\n【Baseline结果】\")\n",
        "    print(f\"Threshold: {best_th_baseline:.4f}\")\n",
        "    print(f\"Test Metrics: {metrics_baseline}\")\n",
        "\n",
        "    # ========== 实验2：记忆增强LSTM ==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验2: 记忆增强LSTM (创新点1)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model_memory = MemoryAugmentedLSTM(vocab_size, emb_dim=128, hidden_dim=256,\n",
        "                                       num_layers=2, dropout=0.3, memory_size=1000)\n",
        "    model_memory = train_model_with_memory(model_memory, train_loader, val_loader, device=device)\n",
        "\n",
        "    # 测试不同alpha值\n",
        "    for alpha in [0.3, 0.5, 0.7]:\n",
        "        print(f\"\\n--- Alpha = {alpha} ---\")\n",
        "        benign_val_hybrid = sequence_scores_hybrid(model_memory, benign_val, window_size,\n",
        "                                                   alpha=alpha, device=device)\n",
        "        malware_val_hybrid = sequence_scores_hybrid(model_memory, malware_val, window_size,\n",
        "                                                    alpha=alpha, device=device)\n",
        "        best_th_hybrid, _ = search_best_threshold(benign_val_hybrid, malware_val_hybrid)\n",
        "\n",
        "        benign_test_hybrid = sequence_scores_hybrid(model_memory, benign_test, window_size,\n",
        "                                                    alpha=alpha, device=device)\n",
        "        malware_test_hybrid = sequence_scores_hybrid(model_memory, malware_test, window_size,\n",
        "                                                     alpha=alpha, device=device)\n",
        "        metrics_hybrid = evaluate(best_th_hybrid, benign_test_hybrid, malware_test_hybrid)\n",
        "\n",
        "        print(f\"Threshold: {best_th_hybrid:.4f}\")\n",
        "        print(f\"Test Metrics: {metrics_hybrid}\")\n",
        "\n",
        "    # ========== 实验3：多窗口集成（不带记忆）==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验3: 多窗口集成 (创新点2)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    ensemble_basic = MultiWindowEnsemble(window_sizes=[10, 20, 30],\n",
        "                                         vocab_size=vocab_size, use_memory=False)\n",
        "    ensemble_basic.train_all(benign_train, benign_val, device)\n",
        "\n",
        "    test_seqs = np.concatenate([benign_test, malware_test])\n",
        "    y_true = np.array([0]*len(benign_test) + [1]*len(malware_test))\n",
        "\n",
        "    for method in ['vote', 'max']:\n",
        "        print(f\"\\n--- Ensemble Method: {method} ---\")\n",
        "        pred_test, _ = ensemble_basic.predict_ensemble(test_seqs, device, method=method)\n",
        "\n",
        "        tp = ((y_true==1)&(pred_test==1)).sum()\n",
        "        tn = ((y_true==0)&(pred_test==0)).sum()\n",
        "        fp = ((y_true==0)&(pred_test==1)).sum()\n",
        "        fn = ((y_true==1)&(pred_test==0)).sum()\n",
        "\n",
        "        precision = tp/(tp+fp+1e-9)\n",
        "        recall = tp/(tp+fn+1e-9)\n",
        "        f1 = 2*precision*recall/(precision+recall+1e-9)\n",
        "        acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "\n",
        "        metrics_ensemble = dict(acc=acc, precision=precision, recall=recall, f1=f1,\n",
        "                               tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "        print(f\"Test Metrics: {metrics_ensemble}\")\n",
        "\n",
        "    # ========== 实验4：记忆增强 + 多窗口集成 ==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验4: 记忆增强多窗口集成 (组合创新)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    ensemble_memory = MultiWindowEnsemble(window_sizes=[10, 20, 30],\n",
        "                                          vocab_size=vocab_size, use_memory=True)\n",
        "    ensemble_memory.train_all(benign_train, benign_val, device)\n",
        "\n",
        "    for method in ['vote', 'max']:\n",
        "        print(f\"\\n--- Ensemble Method: {method} ---\")\n",
        "        pred_test, _ = ensemble_memory.predict_ensemble(test_seqs, device, method=method)\n",
        "\n",
        "        tp = ((y_true==1)&(pred_test==1)).sum()\n",
        "        tn = ((y_true==0)&(pred_test==0)).sum()\n",
        "        fp = ((y_true==0)&(pred_test==1)).sum()\n",
        "        fn = ((y_true==1)&(pred_test==0)).sum()\n",
        "\n",
        "        precision = tp/(tp+fp+1e-9)\n",
        "        recall = tp/(tp+fn+1e-9)\n",
        "        f1 = 2*precision*recall/(precision+recall+1e-9)\n",
        "        acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "\n",
        "        metrics_final = dict(acc=acc, precision=precision, recall=recall, f1=f1,\n",
        "                            tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "        print(f\"Test Metrics: {metrics_final}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# ============ 1. 读数据 + 拆 benign-only ============\n",
        "def load_csv_expanded(path):\n",
        "    df = pd.read_csv(path)\n",
        "    seq_cols = [c for c in df.columns if c.startswith(\"t_\")]\n",
        "    seqs = df[seq_cols].values.astype(int)\n",
        "    labels = df[\"malware\"].values.astype(int)\n",
        "    return seqs, labels\n",
        "\n",
        "def split_benign_only(seqs, labels, seed=42):\n",
        "    benign = seqs[labels == 0]\n",
        "    malware = seqs[labels == 1]\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx_b = rng.permutation(len(benign))\n",
        "    idx_m = rng.permutation(len(malware))\n",
        "\n",
        "    n_b = len(benign)\n",
        "    n_m = len(malware)\n",
        "\n",
        "    n_train = int(0.7*n_b)\n",
        "    n_val   = int(0.1*n_b)\n",
        "\n",
        "    benign_train = benign[idx_b[:n_train]]\n",
        "    benign_val   = benign[idx_b[n_train:n_train+n_val]]\n",
        "    benign_test  = benign[idx_b[n_train+n_val:]]\n",
        "\n",
        "    n_m_val = int(0.2*n_m)\n",
        "    malware_val  = malware[idx_m[:n_m_val]]\n",
        "    malware_test = malware[idx_m[n_m_val:]]\n",
        "\n",
        "    return benign_train, benign_val, benign_test, malware_val, malware_test\n",
        "\n",
        "# ============ 2. 滑动窗口 ============\n",
        "def make_windows(seqs, window_size=10):\n",
        "    X, y = [], []\n",
        "    for s in seqs:\n",
        "        s = s.tolist()\n",
        "        for i in range(len(s) - window_size):\n",
        "            X.append(s[i:i+window_size])\n",
        "            y.append(s[i+window_size])\n",
        "    return np.array(X, dtype=int), np.array(y, dtype=int)\n",
        "\n",
        "# ============ 3. Dataset ============\n",
        "class WindowDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "# ============ 4. LSTM LM ============\n",
        "class LSTMLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, num_layers=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "            dropout=dropout if num_layers>1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.emb(x)\n",
        "        o, _ = self.lstm(e)\n",
        "        last = o[:, -1, :]\n",
        "        return self.fc(last)\n",
        "\n",
        "# ============ 【改进】4.5. 增强版记忆增强LSTM ============\n",
        "class ImprovedMemoryAugmentedLSTM(nn.Module):\n",
        "    \"\"\"改进版记忆增强LSTM：使用余弦相似度 + 更大记忆库\"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, num_layers=2,\n",
        "                 dropout=0.3, memory_size=5000):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "            dropout=dropout if num_layers>1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "        self.register_buffer('memory_bank', torch.zeros(memory_size, hidden_dim))\n",
        "        self.memory_ptr = 0\n",
        "        self.memory_size = memory_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, return_hidden=False):\n",
        "        e = self.emb(x)\n",
        "        o, (h, c) = self.lstm(e)\n",
        "        logits = self.fc(o[:, -1, :])\n",
        "\n",
        "        if return_hidden:\n",
        "            return logits, h[-1]\n",
        "        return logits\n",
        "\n",
        "    def update_memory(self, hidden_states):\n",
        "        with torch.no_grad():\n",
        "            batch_size = hidden_states.size(0)\n",
        "            ptr = self.memory_ptr\n",
        "\n",
        "            if ptr + batch_size <= self.memory_size:\n",
        "                self.memory_bank[ptr:ptr+batch_size] = hidden_states.detach()\n",
        "                self.memory_ptr = (ptr + batch_size) % self.memory_size\n",
        "            else:\n",
        "                remain = self.memory_size - ptr\n",
        "                self.memory_bank[ptr:] = hidden_states[:remain].detach()\n",
        "                self.memory_bank[:batch_size-remain] = hidden_states[remain:].detach()\n",
        "                self.memory_ptr = batch_size - remain\n",
        "\n",
        "    def compute_memory_distance(self, hidden_state):\n",
        "        \"\"\"【改进】使用余弦相似度代替欧氏距离\"\"\"\n",
        "        hidden_norm = F.normalize(hidden_state, dim=1)\n",
        "        memory_norm = F.normalize(self.memory_bank, dim=1)\n",
        "\n",
        "        similarity = torch.mm(hidden_norm, memory_norm.T)\n",
        "        distances = 1 - similarity\n",
        "\n",
        "        k = min(100, self.memory_size)\n",
        "        min_distances, _ = torch.topk(distances, k, largest=False, dim=1)\n",
        "        return min_distances.mean(dim=1)\n",
        "\n",
        "# ============ 【新增】4.6 特征工程 ============\n",
        "def extract_statistical_features(seq):\n",
        "    \"\"\"提取序列的统计特征\"\"\"\n",
        "    seq = seq[seq > 0]\n",
        "    if len(seq) == 0:\n",
        "        return np.zeros(6)\n",
        "\n",
        "    features = []\n",
        "\n",
        "    # 1. API多样性\n",
        "    unique_ratio = len(set(seq)) / len(seq)\n",
        "    features.append(unique_ratio)\n",
        "\n",
        "    # 2. 序列熵\n",
        "    counts = np.bincount(seq)\n",
        "    probs = counts[counts > 0] / len(seq)\n",
        "    seq_entropy = entropy(probs)\n",
        "    features.append(seq_entropy)\n",
        "\n",
        "    # 3. 最长连续重复\n",
        "    max_repeat = 1\n",
        "    current_repeat = 1\n",
        "    for i in range(1, len(seq)):\n",
        "        if seq[i] == seq[i-1]:\n",
        "            current_repeat += 1\n",
        "            max_repeat = max(max_repeat, current_repeat)\n",
        "        else:\n",
        "            current_repeat = 1\n",
        "    features.append(max_repeat / len(seq))\n",
        "\n",
        "    # 4. API调用频率的标准差\n",
        "    unique_apis = list(set(seq))\n",
        "    api_freq = [list(seq).count(api) for api in unique_apis]\n",
        "    features.append(np.std(api_freq) if len(api_freq) > 0 else 0)\n",
        "\n",
        "    # 5. 罕见API比例\n",
        "    rare_count = sum(1 for v in counts if 0 < v < 3)\n",
        "    features.append(rare_count / len(set(seq)) if len(set(seq)) > 0 else 0)\n",
        "\n",
        "    # 6. 平均API转移距离\n",
        "    transitions = np.abs(np.diff(seq))\n",
        "    features.append(np.mean(transitions) if len(transitions) > 0 else 0)\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def extract_features_batch(seqs):\n",
        "    \"\"\"批量提取特征\"\"\"\n",
        "    return np.array([extract_statistical_features(seq) for seq in seqs])\n",
        "\n",
        "# ============ 5. 训练/验证 ============\n",
        "def eval_loss(model, loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            total += crit(model(Xb), yb).item()\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=20, lr=1e-3, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val, best_state = 1e9, None\n",
        "    patience, bad_count = 5, 0\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for Xb, yb in tqdm(train_loader, desc=f\"Epoch {ep}\", leave=False):\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = crit(model(Xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.item() * Xb.size(0)\n",
        "\n",
        "        val_loss = eval_loss(model, val_loader, device)\n",
        "        if ep % 5 == 0 or ep == 1:\n",
        "            print(f\"ep{ep}: train={total/len(train_loader.dataset):.4f}, val={val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "            bad_count = 0\n",
        "        else:\n",
        "            bad_count += 1\n",
        "            if bad_count >= patience:\n",
        "                print(f\"Early stop at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "def train_model_with_memory(model, train_loader, val_loader, epochs=20, lr=1e-3, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val, best_state = 1e9, None\n",
        "    patience, bad_count = 5, 0\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for Xb, yb in tqdm(train_loader, desc=f\"Epoch {ep}\", leave=False):\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "\n",
        "            logits, hidden = model(Xb, return_hidden=True)\n",
        "            loss = crit(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.item() * Xb.size(0)\n",
        "\n",
        "            model.update_memory(hidden)\n",
        "\n",
        "        val_loss = eval_loss_memory(model, val_loader, device)\n",
        "        if ep % 5 == 0 or ep == 1:\n",
        "            print(f\"ep{ep}: train={total/len(train_loader.dataset):.4f}, val={val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "            bad_count = 0\n",
        "        else:\n",
        "            bad_count += 1\n",
        "            if bad_count >= patience:\n",
        "                print(f\"Early stop at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "def eval_loss_memory(model, loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            logits = model(Xb, return_hidden=False)\n",
        "            total += crit(logits, yb).item()\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "# ============ 6. 序列异常分数 ============\n",
        "def sequence_scores_nll(model, seqs, window_size=10, device=\"cuda\"):\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    model.eval()\n",
        "    scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for s in seqs:\n",
        "            X, y = make_windows([s], window_size)\n",
        "            if len(X) == 0:\n",
        "                scores.append(0.0)\n",
        "                continue\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            y = torch.tensor(y, dtype=torch.long).to(device)\n",
        "            nll = crit(model(X), y)\n",
        "            scores.append(nll.mean().item())\n",
        "    return np.array(scores)\n",
        "\n",
        "def sequence_scores_hybrid_improved(model, seqs, window_size=10, device=\"cuda\"):\n",
        "    \"\"\"【改进】自适应加权的混合分数\"\"\"\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    model.eval()\n",
        "    nll_scores = []\n",
        "    mem_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for s in seqs:\n",
        "            X, y = make_windows([s], window_size)\n",
        "            if len(X) == 0:\n",
        "                nll_scores.append(0.0)\n",
        "                mem_scores.append(0.0)\n",
        "                continue\n",
        "\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            y = torch.tensor(y, dtype=torch.long).to(device)\n",
        "\n",
        "            logits, hidden = model(X, return_hidden=True)\n",
        "            nll = crit(logits, y).mean().item()\n",
        "            nll_scores.append(nll)\n",
        "\n",
        "            mem_dist = model.compute_memory_distance(hidden).mean().item()\n",
        "            mem_scores.append(mem_dist)\n",
        "\n",
        "    nll_scores = np.array(nll_scores)\n",
        "    mem_scores = np.array(mem_scores)\n",
        "\n",
        "    # 【改进】使用中位数+IQR归一化\n",
        "    nll_median = np.median(nll_scores)\n",
        "    nll_iqr = np.percentile(nll_scores, 75) - np.percentile(nll_scores, 25)\n",
        "    nll_norm = (nll_scores - nll_median) / (nll_iqr + 1e-8)\n",
        "\n",
        "    mem_median = np.median(mem_scores)\n",
        "    mem_iqr = np.percentile(mem_scores, 75) - np.percentile(mem_scores, 25)\n",
        "    mem_norm = (mem_scores - mem_median) / (mem_iqr + 1e-8)\n",
        "\n",
        "    # 【改进】自适应权重\n",
        "    nll_std = np.std(nll_norm)\n",
        "    mem_std = np.std(mem_norm)\n",
        "    alpha = nll_std / (nll_std + mem_std + 1e-8)\n",
        "\n",
        "    hybrid_scores = alpha * nll_norm + (1 - alpha) * mem_norm\n",
        "    return hybrid_scores, alpha\n",
        "\n",
        "def search_best_threshold(benign_scores, malware_scores):\n",
        "    all_scores = np.concatenate([benign_scores, malware_scores])\n",
        "    cand_th = np.quantile(all_scores, np.linspace(0.7, 0.99, 30))\n",
        "\n",
        "    best_f1, best_th, best_metrics = -1, None, None\n",
        "    for th in cand_th:\n",
        "        m = evaluate(th, benign_scores, malware_scores)\n",
        "        if m[\"f1\"] > best_f1:\n",
        "            best_f1, best_th, best_metrics = m[\"f1\"], th, m\n",
        "    return best_th, best_metrics\n",
        "\n",
        "def evaluate(th, benign_scores, malware_scores):\n",
        "    y_true = np.array([0]*len(benign_scores) + [1]*len(malware_scores))\n",
        "    y_pred = np.array(\n",
        "        [1 if s>th else 0 for s in benign_scores] +\n",
        "        [1 if s>th else 0 for s in malware_scores]\n",
        "    )\n",
        "    tp = ((y_true==1)&(y_pred==1)).sum()\n",
        "    tn = ((y_true==0)&(y_pred==0)).sum()\n",
        "    fp = ((y_true==0)&(y_pred==1)).sum()\n",
        "    fn = ((y_true==1)&(y_pred==0)).sum()\n",
        "\n",
        "    precision = tp/(tp+fp+1e-9)\n",
        "    recall    = tp/(tp+fn+1e-9)\n",
        "    f1        = 2*precision*recall/(precision+recall+1e-9)\n",
        "    acc       = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "    fpr       = fp/(fp+tn+1e-9)\n",
        "    return dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "\n",
        "# ============ 7. 多窗口集成 ============\n",
        "class ImprovedMultiWindowEnsemble:\n",
        "    \"\"\"改进版多窗口集成\"\"\"\n",
        "    def __init__(self, window_sizes=[10, 20, 30], vocab_size=307, use_memory=False):\n",
        "        self.window_sizes = window_sizes\n",
        "        self.vocab_size = vocab_size\n",
        "        self.use_memory = use_memory\n",
        "        self.models = {}\n",
        "        self.thresholds = {}\n",
        "        self.weights = {}\n",
        "\n",
        "    def train_all(self, benign_train, benign_val, malware_val, device=\"cuda\"):\n",
        "        \"\"\"训练所有窗口的模型并计算权重\"\"\"\n",
        "        val_f1_scores = {}\n",
        "\n",
        "        for ws in self.window_sizes:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Training window_size={ws}\")\n",
        "\n",
        "            Xtr, ytr = make_windows(benign_train, ws)\n",
        "            Xva, yva = make_windows(benign_val, ws)\n",
        "\n",
        "            train_loader = DataLoader(WindowDataset(Xtr, ytr), batch_size=256, shuffle=True)\n",
        "            val_loader = DataLoader(WindowDataset(Xva, yva), batch_size=256)\n",
        "\n",
        "            if self.use_memory:\n",
        "                model = ImprovedMemoryAugmentedLSTM(self.vocab_size, emb_dim=128,\n",
        "                                           hidden_dim=256, num_layers=2, dropout=0.3,\n",
        "                                           memory_size=5000)\n",
        "                model = train_model_with_memory(model, train_loader, val_loader, device=device)\n",
        "            else:\n",
        "                model = LSTMLM(self.vocab_size, emb_dim=128,\n",
        "                              hidden_dim=256, num_layers=2, dropout=0.3)\n",
        "                model = train_model(model, train_loader, val_loader, device=device)\n",
        "\n",
        "            self.models[ws] = model\n",
        "\n",
        "            # 在验证集上评估并找最佳阈值\n",
        "            if self.use_memory:\n",
        "                benign_val_scores, _ = sequence_scores_hybrid_improved(model, benign_val, ws, device=device)\n",
        "                malware_val_scores, _ = sequence_scores_hybrid_improved(model, malware_val, ws, device=device)\n",
        "            else:\n",
        "                benign_val_scores = sequence_scores_nll(model, benign_val, ws, device)\n",
        "                malware_val_scores = sequence_scores_nll(model, malware_val, ws, device)\n",
        "\n",
        "            best_th, metrics = search_best_threshold(benign_val_scores, malware_val_scores)\n",
        "            self.thresholds[ws] = best_th\n",
        "            val_f1_scores[ws] = metrics['f1']\n",
        "            print(f\"Val F1: {metrics['f1']:.4f}, Threshold: {best_th:.4f}\")\n",
        "\n",
        "        # 【改进】根据验证集F1计算权重\n",
        "        total_f1 = sum(val_f1_scores.values())\n",
        "        for ws in self.window_sizes:\n",
        "            self.weights[ws] = val_f1_scores[ws] / total_f1\n",
        "            print(f\"Window {ws} weight: {self.weights[ws]:.4f}\")\n",
        "\n",
        "    def predict_ensemble(self, seqs, device=\"cuda\", method='weighted'):\n",
        "        \"\"\"【改进】增加加权融合方法\"\"\"\n",
        "        all_predictions = {}\n",
        "        all_scores = {}\n",
        "\n",
        "        for ws in self.window_sizes:\n",
        "            if self.use_memory:\n",
        "                scores, _ = sequence_scores_hybrid_improved(self.models[ws], seqs, ws, device=device)\n",
        "            else:\n",
        "                scores = sequence_scores_nll(self.models[ws], seqs, ws, device)\n",
        "\n",
        "            predictions = (scores > self.thresholds[ws]).astype(int)\n",
        "            all_predictions[ws] = predictions\n",
        "            all_scores[ws] = scores\n",
        "\n",
        "        if method == 'vote':\n",
        "            stacked = np.stack([all_predictions[ws] for ws in self.window_sizes])\n",
        "            final_pred = (stacked.sum(axis=0) > len(self.window_sizes) / 2).astype(int)\n",
        "\n",
        "        elif method == 'max':\n",
        "            normalized_scores = []\n",
        "            for ws in self.window_sizes:\n",
        "                scores = all_scores[ws]\n",
        "                norm_scores = (scores - scores.mean()) / (scores.std() + 1e-8)\n",
        "                normalized_scores.append(norm_scores)\n",
        "\n",
        "            max_scores = np.max(normalized_scores, axis=0)\n",
        "            threshold = 0\n",
        "            final_pred = (max_scores > threshold).astype(int)\n",
        "\n",
        "        elif method == 'weighted':\n",
        "            normalized_scores = []\n",
        "            for ws in self.window_sizes:\n",
        "                scores = all_scores[ws]\n",
        "                norm_scores = (scores - scores.mean()) / (scores.std() + 1e-8)\n",
        "                normalized_scores.append(norm_scores * self.weights[ws])\n",
        "\n",
        "            weighted_scores = np.sum(normalized_scores, axis=0)\n",
        "            threshold = 0\n",
        "            final_pred = (weighted_scores > threshold).astype(int)\n",
        "\n",
        "        return final_pred, all_scores\n",
        "\n",
        "# ============ 【新增】8. 传统方法对比 ============\n",
        "def train_isolation_forest(benign_train, benign_test, malware_test):\n",
        "    \"\"\"Isolation Forest基准\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"训练 Isolation Forest\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    train_features = extract_features_batch(benign_train)\n",
        "    test_benign_features = extract_features_batch(benign_test)\n",
        "    test_malware_features = extract_features_batch(malware_test)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    train_features = scaler.fit_transform(train_features)\n",
        "    test_benign_features = scaler.transform(test_benign_features)\n",
        "    test_malware_features = scaler.transform(test_malware_features)\n",
        "\n",
        "    clf = IsolationForest(contamination=0.1, random_state=42, n_estimators=100)\n",
        "    clf.fit(train_features)\n",
        "\n",
        "    pred_benign = clf.predict(test_benign_features)\n",
        "    pred_malware = clf.predict(test_malware_features)\n",
        "\n",
        "    pred_benign = (pred_benign == -1).astype(int)\n",
        "    pred_malware = (pred_malware == -1).astype(int)\n",
        "\n",
        "    y_true = np.array([0]*len(benign_test) + [1]*len(malware_test))\n",
        "    y_pred = np.concatenate([pred_benign, pred_malware])\n",
        "\n",
        "    tp = ((y_true==1)&(y_pred==1)).sum()\n",
        "    tn = ((y_true==0)&(y_pred==0)).sum()\n",
        "    fp = ((y_true==0)&(y_pred==1)).sum()\n",
        "    fn = ((y_true==1)&(y_pred==0)).sum()\n",
        "\n",
        "    precision = tp/(tp+fp+1e-9)\n",
        "    recall = tp/(tp+fn+1e-9)\n",
        "    f1 = 2*precision*recall/(precision+recall+1e-9)\n",
        "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "    fpr = fp/(fp+tn+1e-9)\n",
        "\n",
        "    metrics = dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                   tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "\n",
        "    print(f\"Isolation Forest结果: Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
        "    return metrics\n",
        "\n",
        "def train_one_class_svm(benign_train, benign_test, malware_test):\n",
        "    \"\"\"One-Class SVM基准\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"训练 One-Class SVM\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    train_features = extract_features_batch(benign_train)\n",
        "    test_benign_features = extract_features_batch(benign_test)\n",
        "    test_malware_features = extract_features_batch(malware_test)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    train_features = scaler.fit_transform(train_features)\n",
        "    test_benign_features = scaler.transform(test_benign_features)\n",
        "    test_malware_features = scaler.transform(test_malware_features)\n",
        "\n",
        "    clf = OneClassSVM(nu=0.1, kernel='rbf', gamma='auto')\n",
        "    clf.fit(train_features)\n",
        "\n",
        "    pred_benign = clf.predict(test_benign_features)\n",
        "    pred_malware = clf.predict(test_malware_features)\n",
        "\n",
        "    pred_benign = (pred_benign == -1).astype(int)\n",
        "    pred_malware = (pred_malware == -1).astype(int)\n",
        "\n",
        "    y_true = np.array([0]*len(benign_test) + [1]*len(malware_test))\n",
        "    y_pred = np.concatenate([pred_benign, pred_malware])\n",
        "\n",
        "    tp = ((y_true==1)&(y_pred==1)).sum()\n",
        "    tn = ((y_true==0)&(y_pred==0)).sum()\n",
        "    fp = ((y_true==0)&(y_pred==1)).sum()\n",
        "    fn = ((y_true==1)&(y_pred==0)).sum()\n",
        "\n",
        "    precision = tp/(tp+fp+1e-9)\n",
        "    recall = tp/(tp+fn+1e-9)\n",
        "    f1 = 2*precision*recall/(precision+recall+1e-9)\n",
        "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "    fpr = fp/(fp+tn+1e-9)\n",
        "\n",
        "    metrics = dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                   tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "\n",
        "    print(f\"One-Class SVM结果: Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
        "    return metrics\n",
        "\n",
        "# ============ 【新增】9. 可视化 ============\n",
        "def visualize_tsne(model, benign_seqs, malware_seqs, window_size=20, device=\"cuda\", save_path=\"tsne_visualization.png\"):\n",
        "    \"\"\"t-SNE可视化隐空间分布\"\"\"\n",
        "    print(\"\\n生成t-SNE可视化...\")\n",
        "\n",
        "    model.eval()\n",
        "    hidden_states = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for s in benign_seqs[:500]:\n",
        "            X, _ = make_windows([s], window_size)\n",
        "            if len(X) == 0:\n",
        "                continue\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            _, hidden = model(X, return_hidden=True)\n",
        "            hidden_states.append(hidden.mean(0).cpu().numpy())\n",
        "            labels.append(0)\n",
        "\n",
        "        for s in malware_seqs[:500]:\n",
        "            X, _ = make_windows([s], window_size)\n",
        "            if len(X) == 0:\n",
        "                continue\n",
        "            X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "            _, hidden = model(X, return_hidden=True)\n",
        "            hidden_states.append(hidden.mean(0).cpu().numpy())\n",
        "            labels.append(1)\n",
        "\n",
        "    hidden_states = np.array(hidden_states)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "    embeddings_2d = tsne.fit_transform(hidden_states)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(\n",
        "        embeddings_2d[labels==0, 0],\n",
        "        embeddings_2d[labels==0, 1],\n",
        "        c='blue', alpha=0.5, label='Benign', s=20\n",
        "    )\n",
        "    scatter = plt.scatter(\n",
        "        embeddings_2d[labels==1, 0],\n",
        "        embeddings_2d[labels==1, 1],\n",
        "        c='red', alpha=0.5, label='Malware', s=20\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.title('t-SNE Visualization of Hidden States')\n",
        "    plt.xlabel('Dimension 1')\n",
        "    plt.ylabel('Dimension 2')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"可视化已保存到 {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "# ============ 10. 主流程 ============\n",
        "def main():\n",
        "    path = \"./dynamic_api_call_sequence_per_malware_100_0_306.csv\"\n",
        "    seqs, labels = load_csv_expanded(path)\n",
        "    benign_train, benign_val, benign_test, malware_val, malware_test = split_benign_only(seqs, labels)\n",
        "\n",
        "    vocab_size = int(seqs.max()) + 1\n",
        "    print(\"vocab_size:\", vocab_size)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    all_results = {}\n",
        "\n",
        "    # ========== 实验1：原始Baseline ==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验1: 原始Baseline - 单窗口LSTM\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    window_size = 20\n",
        "    Xtr, ytr = make_windows(benign_train, window_size)\n",
        "    Xva, yva = make_windows(benign_val, window_size)\n",
        "\n",
        "    train_loader = DataLoader(WindowDataset(Xtr, ytr), batch_size=256, shuffle=True)\n",
        "    val_loader = DataLoader(WindowDataset(Xva, yva), batch_size=256)\n",
        "\n",
        "    model_baseline = LSTMLM(vocab_size, emb_dim=128, hidden_dim=256, num_layers=2, dropout=0.3)\n",
        "    model_baseline = train_model(model_baseline, train_loader, val_loader, device=device)\n",
        "\n",
        "    benign_val_scores = sequence_scores_nll(model_baseline, benign_val, window_size, device=device)\n",
        "    malware_val_scores = sequence_scores_nll(model_baseline, malware_val, window_size, device=device)\n",
        "    best_th_baseline, _ = search_best_threshold(benign_val_scores, malware_val_scores)\n",
        "\n",
        "    benign_test_scores = sequence_scores_nll(model_baseline, benign_test, window_size, device=device)\n",
        "    malware_test_scores = sequence_scores_nll(model_baseline, malware_test, window_size, device=device)\n",
        "    metrics_baseline = evaluate(best_th_baseline, benign_test_scores, malware_test_scores)\n",
        "\n",
        "    print(f\"\\n【Baseline结果】\")\n",
        "    print(f\"Threshold: {best_th_baseline:.4f}\")\n",
        "    print(f\"Precision: {metrics_baseline['precision']:.4f}, Recall: {metrics_baseline['recall']:.4f}, F1: {metrics_baseline['f1']:.4f}\")\n",
        "    all_results['Baseline (单窗口LSTM)'] = metrics_baseline\n",
        "\n",
        "    # ========== 实验2：改进版记忆增强LSTM ==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验2: 改进版记忆增强LSTM (余弦相似度 + 大记忆库)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model_memory = ImprovedMemoryAugmentedLSTM(vocab_size, emb_dim=128, hidden_dim=256,\n",
        "                                       num_layers=2, dropout=0.3, memory_size=5000)\n",
        "    model_memory = train_model_with_memory(model_memory, train_loader, val_loader, device=device)\n",
        "\n",
        "    benign_val_hybrid, alpha_val = sequence_scores_hybrid_improved(model_memory, benign_val, window_size, device=device)\n",
        "    malware_val_hybrid, _ = sequence_scores_hybrid_improved(model_memory, malware_val, window_size, device=device)\n",
        "    print(f\"自适应权重 alpha (NLL): {alpha_val:.4f}\")\n",
        "\n",
        "    best_th_hybrid, _ = search_best_threshold(benign_val_hybrid, malware_val_hybrid)\n",
        "\n",
        "    benign_test_hybrid, _ = sequence_scores_hybrid_improved(model_memory, benign_test, window_size, device=device)\n",
        "    malware_test_hybrid, _ = sequence_scores_hybrid_improved(model_memory, malware_test, window_size, device=device)\n",
        "    metrics_hybrid = evaluate(best_th_hybrid, benign_test_hybrid, malware_test_hybrid)\n",
        "\n",
        "    print(f\"\\n【改进版记忆增强结果】\")\n",
        "    print(f\"Precision: {metrics_hybrid['precision']:.4f}, Recall: {metrics_hybrid['recall']:.4f}, F1: {metrics_hybrid['f1']:.4f}\")\n",
        "    all_results['改进版记忆增强'] = metrics_hybrid\n",
        "\n",
        "    # ========== 实验3：多窗口集成（不带记忆）==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验3: 改进版多窗口集成\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    ensemble_basic = ImprovedMultiWindowEnsemble(window_sizes=[10, 20, 30],\n",
        "                                         vocab_size=vocab_size, use_memory=False)\n",
        "    ensemble_basic.train_all(benign_train, benign_val, malware_val, device)\n",
        "\n",
        "    test_seqs = np.concatenate([benign_test, malware_test])\n",
        "    y_true = np.array([0]*len(benign_test) + [1]*len(malware_test))\n",
        "\n",
        "    for method in ['vote', 'max', 'weighted']:\n",
        "        print(f\"\\n--- Ensemble Method: {method} ---\")\n",
        "        pred_test, _ = ensemble_basic.predict_ensemble(test_seqs, device, method=method)\n",
        "\n",
        "        tp = ((y_true==1)&(pred_test==1)).sum()\n",
        "        tn = ((y_true==0)&(pred_test==0)).sum()\n",
        "        fp = ((y_true==0)&(pred_test==1)).sum()\n",
        "        fn = ((y_true==1)&(pred_test==0)).sum()\n",
        "\n",
        "        precision = tp/(tp+fp+1e-9)\n",
        "        recall = tp/(tp+fn+1e-9)\n",
        "        f1 = 2*precision*recall/(precision+recall+1e-9)\n",
        "        acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "        fpr = fp/(fp+tn+1e-9)\n",
        "\n",
        "        metrics_ensemble = dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                               tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "        all_results[f'多窗口集成-{method}'] = metrics_ensemble\n",
        "\n",
        "    # ========== 实验4：记忆增强 + 多窗口集成 ==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"实验4: 改进版记忆增强多窗口集成\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    ensemble_memory = ImprovedMultiWindowEnsemble(window_sizes=[10, 20, 30],\n",
        "                                          vocab_size=vocab_size, use_memory=True)\n",
        "    ensemble_memory.train_all(benign_train, benign_val, malware_val, device)\n",
        "\n",
        "    for method in ['vote', 'max', 'weighted']:\n",
        "        print(f\"\\n--- Ensemble Method: {method} ---\")\n",
        "        pred_test, _ = ensemble_memory.predict_ensemble(test_seqs, device, method=method)\n",
        "\n",
        "        tp = ((y_true==1)&(pred_test==1)).sum()\n",
        "        tn = ((y_true==0)&(pred_test==0)).sum()\n",
        "        fp = ((y_true==0)&(pred_test==1)).sum()  # 【修正】这里是bug所在\n",
        "        fn = ((y_true==1)&(pred_test==0)).sum()\n",
        "\n",
        "        precision = tp/(tp+fp+1e-9)\n",
        "        recall = tp/(tp+fn+1e-9)\n",
        "        f1 = 2*precision*recall/(precision+recall+1e-9)\n",
        "        acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
        "        fpr = fp/(fp+tn+1e-9)\n",
        "\n",
        "        metrics_final = dict(acc=acc, precision=precision, recall=recall, f1=f1, fpr=fpr,\n",
        "                            tp=int(tp), tn=int(tn), fp=int(fp), fn=int(fn))\n",
        "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "        all_results[f'记忆增强集成-{method}'] = metrics_final\n",
        "\n",
        "    # ========== 实验5-6：传统方法对比 ==========\n",
        "    metrics_if = train_isolation_forest(benign_train, benign_test, malware_test)\n",
        "    all_results['Isolation Forest'] = metrics_if\n",
        "\n",
        "    metrics_svm = train_one_class_svm(benign_train, benign_test, malware_test)\n",
        "    all_results['One-Class SVM'] = metrics_svm\n",
        "\n",
        "    # ========== 结果汇总 ==========\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"📊 实验结果汇总对比\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(f\"\\n{'方法':<30} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'FPR':<12}\")\n",
        "    print(\"-\" * 78)\n",
        "\n",
        "    for method_name, metrics in all_results.items():\n",
        "        fpr = metrics.get('fpr', metrics['fp']/(metrics['fp']+metrics['tn']))\n",
        "        print(f\"{method_name:<30} {metrics['precision']:<12.4f} {metrics['recall']:<12.4f} {metrics['f1']:<12.4f} {fpr:<12.4f}\")\n",
        "\n",
        "    best_method = max(all_results.items(), key=lambda x: x[1]['f1'])\n",
        "    print(f\"\\n🏆 最佳方法: {best_method[0]}, F1-Score: {best_method[1]['f1']:.4f}\")\n",
        "\n",
        "    baseline_f1 = all_results['Baseline (单窗口LSTM)']['f1']\n",
        "    print(f\"\\n📈 相对Baseline的F1提升:\")\n",
        "    for method_name, metrics in all_results.items():\n",
        "        if method_name != 'Baseline (单窗口LSTM)':\n",
        "            improvement = (metrics['f1'] - baseline_f1) / baseline_f1 * 100\n",
        "            print(f\"{method_name:<30} {improvement:>6.2f}%\")\n",
        "\n",
        "    # ========== 可视化 ==========\n",
        "    visualize_tsne(model_memory, benign_test, malware_test, window_size=20, device=device)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1nwvkRHU08G",
        "outputId": "af36bb7c-84b5-47ce-cdb5-de14e1a0093b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_size: 307\n",
            "\n",
            "======================================================================\n",
            "实验1: 原始Baseline - 单窗口LSTM\n",
            "======================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.3557, val=1.5717\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.7130, val=0.8544\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4260, val=0.7722\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2815, val=0.7920\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stop at epoch 17\n",
            "\n",
            "【Baseline结果】\n",
            "Threshold: 2.4880\n",
            "Precision: 0.9986, Recall: 0.3030, F1: 0.4649\n",
            "\n",
            "======================================================================\n",
            "实验2: 改进版记忆增强LSTM (余弦相似度 + 大记忆库)\n",
            "======================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.3314, val=1.5288\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6889, val=0.8536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4094, val=0.7710\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stop at epoch 14\n",
            "自适应权重 alpha (NLL): 0.5614\n",
            "\n",
            "【改进版记忆增强结果】\n",
            "Precision: 0.9929, Recall: 0.2931, F1: 0.4526\n",
            "\n",
            "======================================================================\n",
            "实验3: 改进版多窗口集成\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training window_size=10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.1945, val=1.4114\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6651, val=0.8402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4064, val=0.7824\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2697, val=0.8214\n",
            "Early stop at epoch 15\n",
            "Val F1: 0.4649, Threshold: 2.4272\n",
            "\n",
            "============================================================\n",
            "Training window_size=20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.3565, val=1.5444\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.7053, val=0.8615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4201, val=0.7709\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2737, val=0.7937\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stop at epoch 17\n",
            "Val F1: 0.4561, Threshold: 2.7140\n",
            "\n",
            "============================================================\n",
            "Training window_size=30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.3431, val=1.5381\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.7115, val=0.8879\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4166, val=0.7874\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2687, val=0.8121\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stop at epoch 17\n",
            "Val F1: 0.4633, Threshold: 2.4865\n",
            "Window 10 weight: 0.3359\n",
            "Window 20 weight: 0.3295\n",
            "Window 30 weight: 0.3347\n",
            "\n",
            "--- Ensemble Method: vote ---\n",
            "Precision: 0.9985, Recall: 0.2916, F1: 0.4514\n",
            "\n",
            "--- Ensemble Method: max ---\n",
            "Precision: 0.9981, Recall: 0.4834, F1: 0.6513\n",
            "\n",
            "--- Ensemble Method: weighted ---\n",
            "Precision: 0.9985, Recall: 0.4690, F1: 0.6383\n",
            "\n",
            "======================================================================\n",
            "实验4: 改进版记忆增强多窗口集成\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training window_size=10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.2257, val=1.4634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6866, val=0.8568\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4136, val=0.7871\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2808, val=0.8083\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stop at epoch 16\n",
            "Val F1: 0.4612, Threshold: 0.4035\n",
            "\n",
            "============================================================\n",
            "Training window_size=20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.2783, val=1.4969\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.6728, val=0.8323\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.3961, val=0.7532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2579, val=0.7693\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stop at epoch 16\n",
            "Val F1: 0.4477, Threshold: 0.4677\n",
            "\n",
            "============================================================\n",
            "Training window_size=30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep1: train=2.4429, val=1.6430\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep5: train=0.7367, val=0.8743\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep10: train=0.4260, val=0.7818\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep15: train=0.2818, val=0.7974\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stop at epoch 16\n",
            "Val F1: 0.4595, Threshold: 0.3618\n",
            "Window 10 weight: 0.3370\n",
            "Window 20 weight: 0.3272\n",
            "Window 30 weight: 0.3358\n",
            "\n",
            "--- Ensemble Method: vote ---\n",
            "Precision: 0.9975, Recall: 0.2979, F1: 0.4588\n",
            "\n",
            "--- Ensemble Method: max ---\n",
            "Precision: 0.9967, Recall: 0.5044, F1: 0.6698\n",
            "\n",
            "--- Ensemble Method: weighted ---\n",
            "Precision: 0.9970, Recall: 0.4926, F1: 0.6594\n",
            "\n",
            "======================================================================\n",
            "训练 Isolation Forest\n",
            "======================================================================\n",
            "Isolation Forest结果: Precision=0.9828, Recall=0.0318, F1=0.0616\n",
            "\n",
            "======================================================================\n",
            "训练 One-Class SVM\n",
            "======================================================================\n",
            "One-Class SVM结果: Precision=0.9969, Recall=0.2045, F1=0.3394\n",
            "\n",
            "======================================================================\n",
            "📊 实验结果汇总对比\n",
            "======================================================================\n",
            "\n",
            "方法                             Precision    Recall       F1-Score     FPR         \n",
            "------------------------------------------------------------------------------\n",
            "Baseline (单窗口LSTM)             0.9986       0.3030       0.4649       0.0691      \n",
            "改进版记忆增强                        0.9929       0.2931       0.4526       0.3318      \n",
            "多窗口集成-vote                     0.9985       0.2916       0.4514       0.0691      \n",
            "多窗口集成-max                      0.9981       0.4834       0.6513       0.1429      \n",
            "多窗口集成-weighted                 0.9985       0.4690       0.6383       0.1106      \n",
            "记忆增强集成-vote                    0.9975       0.2979       0.4588       0.1198      \n",
            "记忆增强集成-max                     0.9967       0.5044       0.6698       0.2673      \n",
            "记忆增强集成-weighted                0.9970       0.4926       0.6594       0.2350      \n",
            "Isolation Forest               0.9828       0.0318       0.0616       0.0876      \n",
            "One-Class SVM                  0.9969       0.2045       0.3394       0.1014      \n",
            "\n",
            "🏆 最佳方法: 记忆增强集成-max, F1-Score: 0.6698\n",
            "\n",
            "📈 相对Baseline的F1提升:\n",
            "改进版记忆增强                         -2.65%\n",
            "多窗口集成-vote                      -2.90%\n",
            "多窗口集成-max                       40.10%\n",
            "多窗口集成-weighted                  37.29%\n",
            "记忆增强集成-vote                     -1.31%\n",
            "记忆增强集成-max                      44.08%\n",
            "记忆增强集成-weighted                 41.85%\n",
            "Isolation Forest               -86.76%\n",
            "One-Class SVM                  -26.99%\n",
            "\n",
            "生成t-SNE可视化...\n",
            "可视化已保存到 tsne_visualization.png\n"
          ]
        }
      ]
    }
  ]
}